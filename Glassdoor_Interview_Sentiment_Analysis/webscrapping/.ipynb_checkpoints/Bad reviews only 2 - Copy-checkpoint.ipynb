{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\jiana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jiana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from matplotlib.pyplot import get_cmap\n",
    "\n",
    "import plotly.express as px\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "import requests\n",
    "from lxml import html\n",
    "import getpass\n",
    "from googletrans import Translator\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager \n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import time\n",
    "import random\n",
    "\n",
    "opts = Options()\n",
    "opts.add_argument('user-agent=polar-bear 3.0')\n",
    "opts.add_argument(\"--headless\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email : ········\n",
      "Password : ········\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 86.0.4240\n",
      "[WDM] - Get LATEST driver version for 86.0.4240\n",
      "[WDM] - Get LATEST driver version for 86.0.4240\n",
      "[WDM] - Trying to download new driver from http://chromedriver.storage.googleapis.com/86.0.4240.22/chromedriver_win32.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver has been saved in cache [C:\\Users\\jiana\\.wdm\\drivers\\chromedriver\\win32\\86.0.4240.22]\n",
      "<ipython-input-3-42d1c69f0a0f>:7: DeprecationWarning: use options instead of chrome_options\n",
      "  driver = webdriver.Chrome(ChromeDriverManager().install(), chrome_options = opts)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Successful!\n"
     ]
    }
   ],
   "source": [
    "# driver = webdriver.Chrome(executable_path = 'C:\\Program Files (x86)\\Google\\Chrome\\Application\\chromedriver.exe', chrome_options = opts)\n",
    "\n",
    "email = getpass.getpass('Email : ')\n",
    "password = getpass.getpass('Password : ')\n",
    "\n",
    "try: \n",
    "    driver = webdriver.Chrome(ChromeDriverManager().install(), chrome_options = opts) \n",
    "    driver.get('https://www.glassdoor.sg/index.htm') \n",
    "    driver.implicitly_wait(15)\n",
    "    \n",
    "    loginpage = driver.find_element_by_xpath('//*[@id=\"TopNav\"]/nav/div/div/div[4]/div[1]/a')\n",
    "    loginpage.click()\n",
    "\n",
    "    loginBox = driver.find_element_by_xpath('//*[@id=\"userEmail\"]') \n",
    "    loginBox.send_keys(email)\n",
    "    \n",
    "    passWordBox = driver.find_element_by_xpath('//*[@id=\"userPassword\"]')\n",
    "    passWordBox.send_keys(password)\n",
    "    \n",
    "    signin = driver.find_element_by_xpath('//*[@id=\"LoginModal\"]/div/div/div[2]/div[2]/div[2]/div/div/div/div[3]/form/div[3]/div[1]/button')\n",
    "    signin.click()\n",
    "    \n",
    "    print('Login Successful!')\n",
    "\n",
    "except:\n",
    "    print('Login Failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page :\n",
      "Refreshing page 1...\n",
      "1 of 93\n",
      "2 of 93\n",
      "3 of 93\n",
      "4 of 93\n",
      "5 of 93\n",
      "6 of 93\n",
      "7 of 93\n",
      "8 of 93\n",
      "9 of 93\n",
      "10 of 93\n",
      "Refreshing page 11...\n",
      "Refreshing page 11...\n",
      "Refreshing page 11...\n",
      "11 of 93\n",
      "12 of 93\n",
      "13 of 93\n",
      "14 of 93\n",
      "15 of 93\n",
      "16 of 93\n",
      "17 of 93\n",
      "18 of 93\n",
      "19 of 93\n",
      "20 of 93\n",
      "21 of 93\n",
      "22 of 93\n",
      "23 of 93\n",
      "24 of 93\n",
      "25 of 93\n",
      "26 of 93\n",
      "27 of 93\n",
      "28 of 93\n",
      "29 of 93\n",
      "30 of 93\n",
      "31 of 93\n",
      "32 of 93\n",
      "33 of 93\n",
      "34 of 93\n",
      "35 of 93\n",
      "36 of 93\n",
      "Pause to rest. Run time : 5.73 minutes\n",
      "\n",
      "Scraping page :\n",
      "37 of 93\n",
      "38 of 93\n",
      "39 of 93\n",
      "40 of 93\n",
      "41 of 93\n",
      "42 of 93\n",
      "43 of 93\n",
      "44 of 93\n",
      "45 of 93\n",
      "46 of 93\n",
      "47 of 93\n",
      "48 of 93\n",
      "49 of 93\n",
      "50 of 93, Run time : 7.5 minutes\n",
      "51 of 93\n",
      "52 of 93\n",
      "53 of 93\n",
      "54 of 93\n",
      "55 of 93\n",
      "56 of 93\n",
      "57 of 93\n",
      "58 of 93\n",
      "59 of 93\n",
      "60 of 93\n",
      "61 of 93\n",
      "62 of 93\n",
      "63 of 93\n",
      "64 of 93\n",
      "65 of 93\n",
      "66 of 93\n",
      "67 of 93\n",
      "68 of 93\n",
      "69 of 93\n",
      "70 of 93\n",
      "Pause to rest. Run time : 9.92 minutes\n",
      "\n",
      "Scraping page :\n",
      "71 of 93\n",
      "72 of 93\n",
      "73 of 93\n",
      "Pause to rest. Run time : 10.49 minutes\n",
      "\n",
      "Scraping page :\n",
      "74 of 93\n",
      "75 of 93\n",
      "76 of 93\n",
      "77 of 93\n",
      "78 of 93\n",
      "79 of 93\n",
      "80 of 93\n",
      "81 of 93\n",
      "82 of 93\n",
      "83 of 93\n",
      "84 of 93\n",
      "85 of 93\n",
      "86 of 93\n",
      "87 of 93\n",
      "88 of 93\n",
      "89 of 93\n",
      "90 of 93\n",
      "91 of 93\n",
      "92 of 93\n",
      "93 of 93\n",
      "\n",
      "Successfully scraped for ebay interviews.\n",
      "Total duration : 13.19 minutes\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.glassdoor.sg/Interview/eBay-Interview-Questions-E7853.htm' # Change URL to company you want\n",
    "next_url = None\n",
    "page = 1\n",
    "num = 0\n",
    "main_dict = []\n",
    "prevent = [37,71]\n",
    "max_page = 94            # Change the page number to the number of pages you want to web scrape\n",
    "start_time = time.time()\n",
    "\n",
    "print('Scraping page :')\n",
    "\n",
    "while page < max_page:\n",
    "    if next_url == None:\n",
    "        next_url = url    \n",
    "    \n",
    "    else:\n",
    "        next_url = 'https://www.glassdoor.com'+after\n",
    "    \n",
    "    if page % prevent[num] == 0:\n",
    "        print(f'Pause to rest. Run time : {round((time.time() - start_time)/60,2)} minutes\\n')\n",
    "        time.sleep(random.randint(3,5))\n",
    "        print('Scraping page :')\n",
    "        num = 1 - num\n",
    "    \n",
    "    driver.get(next_url)\n",
    "    time.sleep(random.randint(1,3))\n",
    "    \n",
    "    post = html.fromstring(driver.page_source)\n",
    "    get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    " \n",
    "    while len(get_id) < 10:\n",
    "        print(f'Refreshing page {page}...')\n",
    "        driver.get(next_url)\n",
    "        time.sleep(random.randint(2,4))\n",
    "        post = html.fromstring(driver.page_source)\n",
    "        get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    "\n",
    "    for i in range(len(get_id)):\n",
    "        \n",
    "        id_pos = get_id[i].attrib['id']\n",
    "        interview_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[1]/p[4]/text()')\n",
    "        question_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[2]/ul/li/span/text()')\n",
    "        offer_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[1]/div/div[2]/span/text()')\n",
    "        experience_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[2]/div/div[2]/span/text()')\n",
    "        difficulty_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[3]/div/div[2]/span/text()')\n",
    "        \n",
    "        page_frame = {}\n",
    "        \n",
    "        if len(interview_) == 1:\n",
    "            page_frame['interview'] = interview_[0]\n",
    "            \n",
    "        if len(question_) == 1:\n",
    "            page_frame['question'] = question_[0]\n",
    "        \n",
    "        if len(offer_) == 1:\n",
    "            page_frame['offer'] = offer_[0]\n",
    "\n",
    "        if len(experience_) == 1:\n",
    "            page_frame['experience'] = experience_[0]\n",
    "\n",
    "        if len(difficulty_) == 1:\n",
    "            page_frame['difficulty'] = difficulty_[0]\n",
    "        \n",
    "        main_dict.append(page_frame)\n",
    "\n",
    "    if page % 50 == 0:\n",
    "        print(f'{page} of {max_page-1}, Run time : {round((time.time() - start_time)/60,2)} minutes')\n",
    "        \n",
    "    else:\n",
    "        print(f'{page} of {max_page-1}')\n",
    "    \n",
    "    page+=1\n",
    "    after = post.xpath('//*[@id=\"FooterPageNav\"]/div[2]/ul/li[7]/a/@href')[0]\n",
    "    ebay_df = pd.DataFrame(main_dict)                                        # Change the data frame and csv name\n",
    "\n",
    "print(f'\\nSuccessfully scraped for ebay interviews.\\nTotal duration : {round((time.time() - start_time)/60,2)} minutes')\n",
    "# Change the name of company you are scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page :\n",
      "1 of 114\n",
      "2 of 114\n",
      "3 of 114\n",
      "4 of 114\n",
      "5 of 114\n",
      "6 of 114\n",
      "7 of 114\n",
      "8 of 114\n",
      "9 of 114\n",
      "10 of 114\n",
      "11 of 114\n",
      "12 of 114\n",
      "13 of 114\n",
      "14 of 114\n",
      "15 of 114\n",
      "16 of 114\n",
      "17 of 114\n",
      "18 of 114\n",
      "19 of 114\n",
      "20 of 114\n",
      "21 of 114\n",
      "22 of 114\n",
      "23 of 114\n",
      "24 of 114\n",
      "25 of 114\n",
      "26 of 114\n",
      "27 of 114\n",
      "28 of 114\n",
      "29 of 114\n",
      "30 of 114\n",
      "31 of 114\n",
      "32 of 114\n",
      "33 of 114\n",
      "34 of 114\n",
      "35 of 114\n",
      "36 of 114\n",
      "Pause to rest. Run time : 4.62 minutes\n",
      "\n",
      "Scraping page :\n",
      "37 of 114\n",
      "38 of 114\n",
      "Refreshing page 39...\n",
      "Refreshing page 39...\n",
      "Refreshing page 39...\n",
      "Refreshing page 39...\n",
      "39 of 114\n",
      "40 of 114\n",
      "41 of 114\n",
      "42 of 114\n",
      "43 of 114\n",
      "44 of 114\n",
      "45 of 114\n",
      "46 of 114\n",
      "47 of 114\n",
      "48 of 114\n",
      "49 of 114\n",
      "50 of 114, Run time : 6.63 minutes\n",
      "51 of 114\n",
      "52 of 114\n",
      "53 of 114\n",
      "54 of 114\n",
      "55 of 114\n",
      "56 of 114\n",
      "57 of 114\n",
      "58 of 114\n",
      "59 of 114\n",
      "60 of 114\n",
      "61 of 114\n",
      "62 of 114\n",
      "63 of 114\n",
      "64 of 114\n",
      "65 of 114\n",
      "66 of 114\n",
      "67 of 114\n",
      "68 of 114\n",
      "69 of 114\n",
      "70 of 114\n",
      "Pause to rest. Run time : 9.04 minutes\n",
      "\n",
      "Scraping page :\n",
      "71 of 114\n",
      "72 of 114\n",
      "73 of 114\n",
      "Pause to rest. Run time : 9.5 minutes\n",
      "\n",
      "Scraping page :\n",
      "74 of 114\n",
      "75 of 114\n",
      "76 of 114\n",
      "77 of 114\n",
      "78 of 114\n",
      "79 of 114\n",
      "80 of 114\n",
      "81 of 114\n",
      "82 of 114\n",
      "83 of 114\n",
      "84 of 114\n",
      "85 of 114\n",
      "86 of 114\n",
      "87 of 114\n",
      "88 of 114\n",
      "89 of 114\n",
      "90 of 114\n",
      "91 of 114\n",
      "92 of 114\n",
      "93 of 114\n",
      "94 of 114\n",
      "95 of 114\n",
      "96 of 114\n",
      "97 of 114\n",
      "98 of 114\n",
      "99 of 114\n",
      "100 of 114, Run time : 12.87 minutes\n",
      "101 of 114\n",
      "102 of 114\n",
      "103 of 114\n",
      "104 of 114\n",
      "105 of 114\n",
      "106 of 114\n",
      "107 of 114\n",
      "108 of 114\n",
      "109 of 114\n",
      "110 of 114\n",
      "111 of 114\n",
      "112 of 114\n",
      "113 of 114\n",
      "114 of 114\n",
      "\n",
      "Successfully scraped for paypal interviews.\n",
      "Total duration : 14.7 minutes\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.glassdoor.sg/Interview/PayPal-Interview-Questions-E9848.htm' # Change URL to company you want\n",
    "next_url = None\n",
    "page = 1\n",
    "num = 0\n",
    "main_dict = []\n",
    "prevent = [37,71]\n",
    "max_page = 115            # Change the page number to the number of pages you want to web scrape\n",
    "start_time = time.time()\n",
    "\n",
    "print('Scraping page :')\n",
    "\n",
    "while page < max_page:\n",
    "    if next_url == None:\n",
    "        next_url = url    \n",
    "    \n",
    "    else:\n",
    "        next_url = 'https://www.glassdoor.com'+after\n",
    "    \n",
    "    if page % prevent[num] == 0:\n",
    "        print(f'Pause to rest. Run time : {round((time.time() - start_time)/60,2)} minutes\\n')\n",
    "        time.sleep(random.randint(3,5))\n",
    "        print('Scraping page :')\n",
    "        num = 1 - num\n",
    "    \n",
    "    driver.get(next_url)\n",
    "    time.sleep(random.randint(1,3))\n",
    "    \n",
    "    post = html.fromstring(driver.page_source)\n",
    "    get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    " \n",
    "    while len(get_id) < 10:\n",
    "        print(f'Refreshing page {page}...')\n",
    "        driver.get(next_url)\n",
    "        time.sleep(random.randint(2,4))\n",
    "        post = html.fromstring(driver.page_source)\n",
    "        get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    "\n",
    "    for i in range(len(get_id)):\n",
    "        \n",
    "        id_pos = get_id[i].attrib['id']\n",
    "        interview_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[1]/p[4]/text()')\n",
    "        question_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[2]/ul/li/span/text()')\n",
    "        offer_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[1]/div/div[2]/span/text()')\n",
    "        experience_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[2]/div/div[2]/span/text()')\n",
    "        difficulty_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[3]/div/div[2]/span/text()')\n",
    "        \n",
    "        page_frame = {}\n",
    "        \n",
    "        if len(interview_) == 1:\n",
    "            page_frame['interview'] = interview_[0]\n",
    "            \n",
    "        if len(question_) == 1:\n",
    "            page_frame['question'] = question_[0]\n",
    "        \n",
    "        if len(offer_) == 1:\n",
    "            page_frame['offer'] = offer_[0]\n",
    "\n",
    "        if len(experience_) == 1:\n",
    "            page_frame['experience'] = experience_[0]\n",
    "\n",
    "        if len(difficulty_) == 1:\n",
    "            page_frame['difficulty'] = difficulty_[0]\n",
    "        \n",
    "        main_dict.append(page_frame)\n",
    "\n",
    "    if page % 50 == 0:\n",
    "        print(f'{page} of {max_page-1}, Run time : {round((time.time() - start_time)/60,2)} minutes')\n",
    "        \n",
    "    else:\n",
    "        print(f'{page} of {max_page-1}')\n",
    "    \n",
    "    page+=1\n",
    "    after = post.xpath('//*[@id=\"FooterPageNav\"]/div[2]/ul/li[7]/a/@href')[0]\n",
    "    paypal_df = pd.DataFrame(main_dict)                                        # Change the data frame and csv name\n",
    "\n",
    "print(f'\\nSuccessfully scraped for paypal interviews.\\nTotal duration : {round((time.time() - start_time)/60,2)} minutes')\n",
    "# Change the name of company you are scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page :\n",
      "1 of 112\n",
      "2 of 112\n",
      "3 of 112\n",
      "4 of 112\n",
      "5 of 112\n",
      "6 of 112\n",
      "7 of 112\n",
      "8 of 112\n",
      "9 of 112\n",
      "10 of 112\n",
      "11 of 112\n",
      "12 of 112\n",
      "13 of 112\n",
      "14 of 112\n",
      "15 of 112\n",
      "16 of 112\n",
      "17 of 112\n",
      "18 of 112\n",
      "19 of 112\n",
      "20 of 112\n",
      "21 of 112\n",
      "22 of 112\n",
      "23 of 112\n",
      "24 of 112\n",
      "25 of 112\n",
      "26 of 112\n",
      "27 of 112\n",
      "28 of 112\n",
      "29 of 112\n",
      "30 of 112\n",
      "31 of 112\n",
      "32 of 112\n",
      "33 of 112\n",
      "34 of 112\n",
      "35 of 112\n",
      "36 of 112\n",
      "Pause to rest. Run time : 4.4 minutes\n",
      "\n",
      "Scraping page :\n",
      "37 of 112\n",
      "38 of 112\n",
      "39 of 112\n",
      "40 of 112\n",
      "41 of 112\n",
      "42 of 112\n",
      "43 of 112\n",
      "44 of 112\n",
      "45 of 112\n",
      "46 of 112\n",
      "47 of 112\n",
      "48 of 112\n",
      "49 of 112\n",
      "50 of 112, Run time : 6.1 minutes\n",
      "51 of 112\n",
      "52 of 112\n",
      "53 of 112\n",
      "54 of 112\n",
      "55 of 112\n",
      "56 of 112\n",
      "57 of 112\n",
      "58 of 112\n",
      "59 of 112\n",
      "60 of 112\n",
      "61 of 112\n",
      "62 of 112\n",
      "63 of 112\n",
      "64 of 112\n",
      "65 of 112\n",
      "66 of 112\n",
      "67 of 112\n",
      "68 of 112\n",
      "69 of 112\n",
      "70 of 112\n",
      "Pause to rest. Run time : 8.54 minutes\n",
      "\n",
      "Scraping page :\n",
      "71 of 112\n",
      "72 of 112\n",
      "73 of 112\n",
      "Pause to rest. Run time : 9.0 minutes\n",
      "\n",
      "Scraping page :\n",
      "74 of 112\n",
      "75 of 112\n",
      "76 of 112\n",
      "77 of 112\n",
      "78 of 112\n",
      "79 of 112\n",
      "80 of 112\n",
      "81 of 112\n",
      "82 of 112\n",
      "83 of 112\n",
      "84 of 112\n",
      "85 of 112\n",
      "86 of 112\n",
      "87 of 112\n",
      "88 of 112\n",
      "89 of 112\n",
      "90 of 112\n",
      "91 of 112\n",
      "92 of 112\n",
      "93 of 112\n",
      "94 of 112\n",
      "95 of 112\n",
      "96 of 112\n",
      "97 of 112\n",
      "98 of 112\n",
      "99 of 112\n",
      "100 of 112, Run time : 12.23 minutes\n",
      "101 of 112\n",
      "102 of 112\n",
      "103 of 112\n",
      "104 of 112\n",
      "105 of 112\n",
      "106 of 112\n",
      "107 of 112\n",
      "108 of 112\n",
      "109 of 112\n",
      "110 of 112\n",
      "111 of 112\n",
      "112 of 112\n",
      "\n",
      "Successfully scraped for Hub Spot interviews.\n",
      "Total duration : 13.55 minutes\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.glassdoor.sg/Interview/HubSpot-Interview-Questions-E227605.htm' # Change URL to company you want\n",
    "next_url = None\n",
    "page = 1\n",
    "num = 0\n",
    "main_dict = []\n",
    "prevent = [37,71]\n",
    "max_page = 113            # Change the page number to the number of pages you want to web scrape\n",
    "start_time = time.time()\n",
    "\n",
    "print('Scraping page :')\n",
    "\n",
    "while page < max_page:\n",
    "    if next_url == None:\n",
    "        next_url = url    \n",
    "    \n",
    "    else:\n",
    "        next_url = 'https://www.glassdoor.com'+after\n",
    "    \n",
    "    if page % prevent[num] == 0:\n",
    "        print(f'Pause to rest. Run time : {round((time.time() - start_time)/60,2)} minutes\\n')\n",
    "        time.sleep(random.randint(3,5))\n",
    "        print('Scraping page :')\n",
    "        num = 1 - num\n",
    "    \n",
    "    driver.get(next_url)\n",
    "    time.sleep(random.randint(1,3))\n",
    "    \n",
    "    post = html.fromstring(driver.page_source)\n",
    "    get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    " \n",
    "    while len(get_id) < 10:\n",
    "        print(f'Refreshing page {page}...')\n",
    "        driver.get(next_url)\n",
    "        time.sleep(random.randint(2,4))\n",
    "        post = html.fromstring(driver.page_source)\n",
    "        get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    "\n",
    "    for i in range(len(get_id)):\n",
    "        \n",
    "        id_pos = get_id[i].attrib['id']\n",
    "        interview_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[1]/p[4]/text()')\n",
    "        question_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[2]/ul/li/span/text()')\n",
    "        offer_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[1]/div/div[2]/span/text()')\n",
    "        experience_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[2]/div/div[2]/span/text()')\n",
    "        difficulty_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[3]/div/div[2]/span/text()')\n",
    "        \n",
    "        page_frame = {}\n",
    "        \n",
    "        if len(interview_) == 1:\n",
    "            page_frame['interview'] = interview_[0]\n",
    "            \n",
    "        if len(question_) == 1:\n",
    "            page_frame['question'] = question_[0]\n",
    "        \n",
    "        if len(offer_) == 1:\n",
    "            page_frame['offer'] = offer_[0]\n",
    "\n",
    "        if len(experience_) == 1:\n",
    "            page_frame['experience'] = experience_[0]\n",
    "\n",
    "        if len(difficulty_) == 1:\n",
    "            page_frame['difficulty'] = difficulty_[0]\n",
    "        \n",
    "        main_dict.append(page_frame)\n",
    "\n",
    "    if page % 50 == 0:\n",
    "        print(f'{page} of {max_page-1}, Run time : {round((time.time() - start_time)/60,2)} minutes')\n",
    "        \n",
    "    else:\n",
    "        print(f'{page} of {max_page-1}')\n",
    "    \n",
    "    page+=1\n",
    "    after = post.xpath('//*[@id=\"FooterPageNav\"]/div[2]/ul/li[7]/a/@href')[0]\n",
    "    hubspot_df = pd.DataFrame(main_dict)                                        # Change the data frame and csv name\n",
    "\n",
    "print(f'\\nSuccessfully scraped for Hub Spot interviews.\\nTotal duration : {round((time.time() - start_time)/60,2)} minutes')\n",
    "# Change the name of company you are scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page :\n",
      "1 of 47\n",
      "2 of 47\n",
      "3 of 47\n",
      "4 of 47\n",
      "5 of 47\n",
      "6 of 47\n",
      "7 of 47\n",
      "8 of 47\n",
      "9 of 47\n",
      "10 of 47\n",
      "11 of 47\n",
      "12 of 47\n",
      "13 of 47\n",
      "14 of 47\n",
      "15 of 47\n",
      "16 of 47\n",
      "17 of 47\n",
      "18 of 47\n",
      "19 of 47\n",
      "20 of 47\n",
      "21 of 47\n",
      "22 of 47\n",
      "23 of 47\n",
      "24 of 47\n",
      "25 of 47\n",
      "26 of 47\n",
      "27 of 47\n",
      "28 of 47\n",
      "29 of 47\n",
      "30 of 47\n",
      "31 of 47\n",
      "32 of 47\n",
      "33 of 47\n",
      "34 of 47\n",
      "35 of 47\n",
      "36 of 47\n",
      "Pause to rest. Run time : 4.42 minutes\n",
      "\n",
      "Scraping page :\n",
      "37 of 47\n",
      "38 of 47\n",
      "39 of 47\n",
      "40 of 47\n",
      "41 of 47\n",
      "42 of 47\n",
      "43 of 47\n",
      "44 of 47\n",
      "45 of 47\n",
      "46 of 47\n",
      "47 of 47\n",
      "\n",
      "Successfully scraped for DocuSign interviews.\n",
      "Total duration : 5.8 minutes\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.glassdoor.sg/Interview/DocuSign-Interview-Questions-E307604.htm' # Change URL to company you want\n",
    "next_url = None\n",
    "page = 1\n",
    "num = 0\n",
    "main_dict = []\n",
    "prevent = [37,71]\n",
    "max_page = 48            # Change the page number to the number of pages you want to web scrape\n",
    "start_time = time.time()\n",
    "\n",
    "print('Scraping page :')\n",
    "\n",
    "while page < max_page:\n",
    "    if next_url == None:\n",
    "        next_url = url    \n",
    "    \n",
    "    else:\n",
    "        next_url = 'https://www.glassdoor.com'+after\n",
    "    \n",
    "    if page % prevent[num] == 0:\n",
    "        print(f'Pause to rest. Run time : {round((time.time() - start_time)/60,2)} minutes\\n')\n",
    "        time.sleep(random.randint(3,5))\n",
    "        print('Scraping page :')\n",
    "        num = 1 - num\n",
    "    \n",
    "    driver.get(next_url)\n",
    "    time.sleep(random.randint(1,3))\n",
    "    \n",
    "    post = html.fromstring(driver.page_source)\n",
    "    get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    " \n",
    "    while len(get_id) < 10:\n",
    "        print(f'Refreshing page {page}...')\n",
    "        driver.get(next_url)\n",
    "        time.sleep(random.randint(2,4))\n",
    "        post = html.fromstring(driver.page_source)\n",
    "        get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    "\n",
    "    for i in range(len(get_id)):\n",
    "        \n",
    "        id_pos = get_id[i].attrib['id']\n",
    "        interview_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[1]/p[4]/text()')\n",
    "        question_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[2]/ul/li/span/text()')\n",
    "        offer_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[1]/div/div[2]/span/text()')\n",
    "        experience_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[2]/div/div[2]/span/text()')\n",
    "        difficulty_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[3]/div/div[2]/span/text()')\n",
    "        \n",
    "        page_frame = {}\n",
    "        \n",
    "        if len(interview_) == 1:\n",
    "            page_frame['interview'] = interview_[0]\n",
    "            \n",
    "        if len(question_) == 1:\n",
    "            page_frame['question'] = question_[0]\n",
    "        \n",
    "        if len(offer_) == 1:\n",
    "            page_frame['offer'] = offer_[0]\n",
    "\n",
    "        if len(experience_) == 1:\n",
    "            page_frame['experience'] = experience_[0]\n",
    "\n",
    "        if len(difficulty_) == 1:\n",
    "            page_frame['difficulty'] = difficulty_[0]\n",
    "        \n",
    "        main_dict.append(page_frame)\n",
    "\n",
    "    if page % 50 == 0:\n",
    "        print(f'{page} of {max_page-1}, Run time : {round((time.time() - start_time)/60,2)} minutes')\n",
    "        \n",
    "    else:\n",
    "        print(f'{page} of {max_page-1}')\n",
    "    \n",
    "    page+=1\n",
    "    after = post.xpath('//*[@id=\"FooterPageNav\"]/div[2]/ul/li[7]/a/@href')[0]\n",
    "    docusign_df = pd.DataFrame(main_dict)                                        # Change the data frame and csv name\n",
    "\n",
    "print(f'\\nSuccessfully scraped for DocuSign interviews.\\nTotal duration : {round((time.time() - start_time)/60,2)} minutes')\n",
    "# Change the name of company you are scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page :\n",
      "1 of 131\n",
      "2 of 131\n",
      "3 of 131\n",
      "4 of 131\n",
      "5 of 131\n",
      "6 of 131\n",
      "7 of 131\n",
      "8 of 131\n",
      "9 of 131\n",
      "10 of 131\n",
      "11 of 131\n",
      "12 of 131\n",
      "13 of 131\n",
      "14 of 131\n",
      "15 of 131\n",
      "16 of 131\n",
      "17 of 131\n",
      "18 of 131\n",
      "19 of 131\n",
      "20 of 131\n",
      "21 of 131\n",
      "22 of 131\n",
      "23 of 131\n",
      "24 of 131\n",
      "25 of 131\n",
      "26 of 131\n",
      "27 of 131\n",
      "28 of 131\n",
      "29 of 131\n",
      "30 of 131\n",
      "31 of 131\n",
      "32 of 131\n",
      "33 of 131\n",
      "34 of 131\n",
      "35 of 131\n",
      "36 of 131\n",
      "Pause to rest. Run time : 4.59 minutes\n",
      "\n",
      "Scraping page :\n",
      "37 of 131\n",
      "38 of 131\n",
      "39 of 131\n",
      "40 of 131\n",
      "41 of 131\n",
      "42 of 131\n",
      "43 of 131\n",
      "44 of 131\n",
      "45 of 131\n",
      "46 of 131\n",
      "47 of 131\n",
      "48 of 131\n",
      "49 of 131\n",
      "50 of 131, Run time : 6.53 minutes\n",
      "51 of 131\n",
      "52 of 131\n",
      "53 of 131\n",
      "54 of 131\n",
      "55 of 131\n",
      "56 of 131\n",
      "57 of 131\n",
      "58 of 131\n",
      "59 of 131\n",
      "60 of 131\n",
      "61 of 131\n",
      "62 of 131\n",
      "63 of 131\n",
      "64 of 131\n",
      "65 of 131\n",
      "66 of 131\n",
      "67 of 131\n",
      "68 of 131\n",
      "69 of 131\n",
      "70 of 131\n",
      "Pause to rest. Run time : 9.39 minutes\n",
      "\n",
      "Scraping page :\n",
      "71 of 131\n",
      "72 of 131\n",
      "73 of 131\n",
      "Pause to rest. Run time : 9.84 minutes\n",
      "\n",
      "Scraping page :\n",
      "Refreshing page 74...\n",
      "Refreshing page 74...\n",
      "Refreshing page 74...\n",
      "Refreshing page 74...\n",
      "Refreshing page 74...\n",
      "74 of 131\n",
      "75 of 131\n",
      "76 of 131\n",
      "77 of 131\n",
      "78 of 131\n",
      "79 of 131\n",
      "80 of 131\n",
      "81 of 131\n",
      "82 of 131\n",
      "83 of 131\n",
      "84 of 131\n",
      "85 of 131\n",
      "86 of 131\n",
      "87 of 131\n",
      "88 of 131\n",
      "89 of 131\n",
      "90 of 131\n",
      "91 of 131\n",
      "92 of 131\n",
      "93 of 131\n",
      "94 of 131\n",
      "95 of 131\n",
      "96 of 131\n",
      "97 of 131\n",
      "98 of 131\n",
      "99 of 131\n",
      "100 of 131, Run time : 14.14 minutes\n",
      "101 of 131\n",
      "102 of 131\n",
      "103 of 131\n",
      "104 of 131\n",
      "105 of 131\n",
      "106 of 131\n",
      "107 of 131\n",
      "108 of 131\n",
      "109 of 131\n",
      "110 of 131\n",
      "111 of 131\n",
      "112 of 131\n",
      "113 of 131\n",
      "114 of 131\n",
      "115 of 131\n",
      "116 of 131\n",
      "117 of 131\n",
      "118 of 131\n",
      "119 of 131\n",
      "120 of 131\n",
      "121 of 131\n",
      "122 of 131\n",
      "123 of 131\n",
      "124 of 131\n",
      "125 of 131\n",
      "126 of 131\n",
      "127 of 131\n",
      "128 of 131\n",
      "129 of 131\n",
      "130 of 131\n",
      "131 of 131\n",
      "\n",
      "Successfully scraped for nvidia interviews.\n",
      "Total duration : 18.19 minutes\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.glassdoor.sg/Interview/NVIDIA-Interview-Questions-E7633.htm' # Change URL to company you want\n",
    "next_url = None\n",
    "page = 1\n",
    "num = 0\n",
    "main_dict = []\n",
    "prevent = [37,71]\n",
    "max_page = 132            # Change the page number to the number of pages you want to web scrape\n",
    "start_time = time.time()\n",
    "\n",
    "print('Scraping page :')\n",
    "\n",
    "while page < max_page:\n",
    "    if next_url == None:\n",
    "        next_url = url    \n",
    "    \n",
    "    else:\n",
    "        next_url = 'https://www.glassdoor.com'+after\n",
    "    \n",
    "    if page % prevent[num] == 0:\n",
    "        print(f'Pause to rest. Run time : {round((time.time() - start_time)/60,2)} minutes\\n')\n",
    "        time.sleep(random.randint(3,5))\n",
    "        print('Scraping page :')\n",
    "        num = 1 - num\n",
    "    \n",
    "    driver.get(next_url)\n",
    "    time.sleep(random.randint(1,3))\n",
    "    \n",
    "    post = html.fromstring(driver.page_source)\n",
    "    get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    " \n",
    "    while len(get_id) < 10:\n",
    "        print(f'Refreshing page {page}...')\n",
    "        driver.get(next_url)\n",
    "        time.sleep(random.randint(2,4))\n",
    "        post = html.fromstring(driver.page_source)\n",
    "        get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    "\n",
    "    for i in range(len(get_id)):\n",
    "        \n",
    "        id_pos = get_id[i].attrib['id']\n",
    "        interview_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[1]/p[4]/text()')\n",
    "        question_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[2]/ul/li/span/text()')\n",
    "        offer_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[1]/div/div[2]/span/text()')\n",
    "        experience_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[2]/div/div[2]/span/text()')\n",
    "        difficulty_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[3]/div/div[2]/span/text()')\n",
    "        \n",
    "        page_frame = {}\n",
    "        \n",
    "        if len(interview_) == 1:\n",
    "            page_frame['interview'] = interview_[0]\n",
    "            \n",
    "        if len(question_) == 1:\n",
    "            page_frame['question'] = question_[0]\n",
    "        \n",
    "        if len(offer_) == 1:\n",
    "            page_frame['offer'] = offer_[0]\n",
    "\n",
    "        if len(experience_) == 1:\n",
    "            page_frame['experience'] = experience_[0]\n",
    "\n",
    "        if len(difficulty_) == 1:\n",
    "            page_frame['difficulty'] = difficulty_[0]\n",
    "        \n",
    "        main_dict.append(page_frame)\n",
    "\n",
    "    if page % 50 == 0:\n",
    "        print(f'{page} of {max_page-1}, Run time : {round((time.time() - start_time)/60,2)} minutes')\n",
    "        \n",
    "    else:\n",
    "        print(f'{page} of {max_page-1}')\n",
    "    \n",
    "    page+=1\n",
    "    after = post.xpath('//*[@id=\"FooterPageNav\"]/div[2]/ul/li[7]/a/@href')[0]\n",
    "    nvidia_df = pd.DataFrame(main_dict)                                        # Change the data frame and csv name\n",
    "\n",
    "print(f'\\nSuccessfully scraped for nvidia interviews.\\nTotal duration : {round((time.time() - start_time)/60,2)} minutes')\n",
    "# Change the name of company you are scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page :\n",
      "1 of 539\n",
      "2 of 539\n",
      "3 of 539\n",
      "4 of 539\n",
      "5 of 539\n",
      "6 of 539\n",
      "7 of 539\n",
      "8 of 539\n",
      "9 of 539\n",
      "10 of 539\n",
      "11 of 539\n",
      "12 of 539\n",
      "13 of 539\n",
      "14 of 539\n",
      "15 of 539\n",
      "16 of 539\n",
      "17 of 539\n",
      "18 of 539\n",
      "19 of 539\n",
      "20 of 539\n",
      "21 of 539\n",
      "22 of 539\n",
      "23 of 539\n",
      "24 of 539\n",
      "25 of 539\n",
      "26 of 539\n",
      "27 of 539\n",
      "28 of 539\n",
      "29 of 539\n",
      "30 of 539\n",
      "31 of 539\n",
      "32 of 539\n",
      "33 of 539\n",
      "34 of 539\n",
      "35 of 539\n",
      "36 of 539\n",
      "Pause to rest. Run time : 4.71 minutes\n",
      "\n",
      "Scraping page :\n",
      "37 of 539\n",
      "38 of 539\n",
      "39 of 539\n",
      "40 of 539\n",
      "41 of 539\n",
      "42 of 539\n",
      "43 of 539\n",
      "44 of 539\n",
      "45 of 539\n",
      "46 of 539\n",
      "47 of 539\n",
      "48 of 539\n",
      "49 of 539\n",
      "50 of 539, Run time : 6.74 minutes\n",
      "51 of 539\n",
      "52 of 539\n",
      "53 of 539\n",
      "54 of 539\n",
      "55 of 539\n",
      "56 of 539\n",
      "57 of 539\n",
      "58 of 539\n",
      "59 of 539\n",
      "60 of 539\n",
      "61 of 539\n",
      "62 of 539\n",
      "63 of 539\n",
      "64 of 539\n",
      "65 of 539\n",
      "66 of 539\n",
      "67 of 539\n",
      "68 of 539\n",
      "69 of 539\n",
      "70 of 539\n",
      "Pause to rest. Run time : 9.62 minutes\n",
      "\n",
      "Scraping page :\n",
      "71 of 539\n",
      "72 of 539\n",
      "73 of 539\n",
      "Pause to rest. Run time : 10.17 minutes\n",
      "\n",
      "Scraping page :\n",
      "74 of 539\n",
      "75 of 539\n",
      "76 of 539\n",
      "77 of 539\n",
      "78 of 539\n",
      "79 of 539\n",
      "80 of 539\n",
      "81 of 539\n",
      "82 of 539\n",
      "83 of 539\n",
      "84 of 539\n",
      "85 of 539\n",
      "86 of 539\n",
      "87 of 539\n",
      "88 of 539\n",
      "89 of 539\n",
      "90 of 539\n",
      "91 of 539\n",
      "92 of 539\n",
      "93 of 539\n",
      "94 of 539\n",
      "95 of 539\n",
      "96 of 539\n",
      "97 of 539\n",
      "98 of 539\n",
      "99 of 539\n",
      "100 of 539, Run time : 14.22 minutes\n",
      "101 of 539\n",
      "102 of 539\n",
      "103 of 539\n",
      "104 of 539\n",
      "105 of 539\n",
      "106 of 539\n",
      "107 of 539\n",
      "108 of 539\n",
      "109 of 539\n",
      "110 of 539\n",
      "111 of 539\n",
      "112 of 539\n",
      "113 of 539\n",
      "114 of 539\n",
      "115 of 539\n",
      "116 of 539\n",
      "117 of 539\n",
      "118 of 539\n",
      "119 of 539\n",
      "120 of 539\n",
      "121 of 539\n",
      "122 of 539\n",
      "123 of 539\n",
      "124 of 539\n",
      "125 of 539\n",
      "126 of 539\n",
      "127 of 539\n",
      "128 of 539\n",
      "129 of 539\n",
      "130 of 539\n",
      "131 of 539\n",
      "132 of 539\n",
      "133 of 539\n",
      "134 of 539\n",
      "135 of 539\n",
      "136 of 539\n",
      "137 of 539\n",
      "138 of 539\n",
      "139 of 539\n",
      "140 of 539\n",
      "141 of 539\n",
      "Pause to rest. Run time : 19.92 minutes\n",
      "\n",
      "Scraping page :\n",
      "142 of 539\n",
      "143 of 539\n",
      "144 of 539\n",
      "145 of 539\n",
      "146 of 539\n",
      "147 of 539\n",
      "Pause to rest. Run time : 20.81 minutes\n",
      "\n",
      "Scraping page :\n",
      "148 of 539\n",
      "149 of 539\n",
      "150 of 539, Run time : 21.28 minutes\n",
      "151 of 539\n",
      "152 of 539\n",
      "153 of 539\n",
      "154 of 539\n",
      "155 of 539\n",
      "156 of 539\n",
      "157 of 539\n",
      "158 of 539\n",
      "159 of 539\n",
      "160 of 539\n",
      "161 of 539\n",
      "162 of 539\n",
      "163 of 539\n",
      "164 of 539\n",
      "165 of 539\n",
      "166 of 539\n",
      "167 of 539\n",
      "168 of 539\n",
      "169 of 539\n",
      "170 of 539\n",
      "171 of 539\n",
      "172 of 539\n",
      "173 of 539\n",
      "174 of 539\n",
      "175 of 539\n",
      "176 of 539\n",
      "177 of 539\n",
      "178 of 539\n",
      "179 of 539\n",
      "180 of 539\n",
      "181 of 539\n",
      "182 of 539\n",
      "183 of 539\n",
      "184 of 539\n",
      "185 of 539\n",
      "186 of 539\n",
      "187 of 539\n",
      "188 of 539\n",
      "189 of 539\n",
      "190 of 539\n",
      "191 of 539\n",
      "192 of 539\n",
      "193 of 539\n",
      "194 of 539\n",
      "195 of 539\n",
      "196 of 539\n",
      "197 of 539\n",
      "198 of 539\n",
      "199 of 539\n",
      "200 of 539, Run time : 28.0 minutes\n",
      "201 of 539\n",
      "202 of 539\n",
      "203 of 539\n",
      "204 of 539\n",
      "205 of 539\n",
      "206 of 539\n",
      "207 of 539\n",
      "208 of 539\n",
      "209 of 539\n",
      "210 of 539\n",
      "211 of 539\n",
      "212 of 539\n",
      "Pause to rest. Run time : 29.66 minutes\n",
      "\n",
      "Scraping page :\n",
      "213 of 539\n",
      "214 of 539\n",
      "215 of 539\n",
      "216 of 539\n",
      "217 of 539\n",
      "218 of 539\n",
      "219 of 539\n",
      "220 of 539\n",
      "221 of 539\n",
      "Pause to rest. Run time : 31.14 minutes\n",
      "\n",
      "Scraping page :\n",
      "222 of 539\n",
      "223 of 539\n",
      "224 of 539\n",
      "225 of 539\n",
      "226 of 539\n",
      "227 of 539\n",
      "228 of 539\n",
      "229 of 539\n",
      "230 of 539\n",
      "231 of 539\n",
      "232 of 539\n",
      "233 of 539\n",
      "234 of 539\n",
      "235 of 539\n",
      "236 of 539\n",
      "237 of 539\n",
      "238 of 539\n",
      "239 of 539\n",
      "240 of 539\n",
      "241 of 539\n",
      "242 of 539\n",
      "243 of 539\n",
      "244 of 539\n",
      "245 of 539\n",
      "246 of 539\n",
      "247 of 539\n",
      "248 of 539\n",
      "249 of 539\n",
      "250 of 539, Run time : 37.03 minutes\n",
      "251 of 539\n",
      "252 of 539\n",
      "253 of 539\n",
      "254 of 539\n",
      "255 of 539\n",
      "256 of 539\n",
      "257 of 539\n",
      "258 of 539\n",
      "259 of 539\n",
      "260 of 539\n",
      "261 of 539\n",
      "262 of 539\n",
      "263 of 539\n",
      "264 of 539\n",
      "265 of 539\n",
      "266 of 539\n",
      "267 of 539\n",
      "268 of 539\n",
      "269 of 539\n",
      "270 of 539\n",
      "271 of 539\n",
      "272 of 539\n",
      "273 of 539\n",
      "274 of 539\n",
      "275 of 539\n",
      "276 of 539\n",
      "277 of 539\n",
      "278 of 539\n",
      "279 of 539\n",
      "280 of 539\n",
      "281 of 539\n",
      "282 of 539\n",
      "283 of 539\n",
      "Pause to rest. Run time : 43.14 minutes\n",
      "\n",
      "Scraping page :\n",
      "284 of 539\n",
      "285 of 539\n",
      "286 of 539\n",
      "287 of 539\n",
      "288 of 539\n",
      "289 of 539\n",
      "290 of 539\n",
      "291 of 539\n",
      "292 of 539\n",
      "293 of 539\n",
      "294 of 539\n",
      "295 of 539\n",
      "Pause to rest. Run time : 45.38 minutes\n",
      "\n",
      "Scraping page :\n",
      "296 of 539\n",
      "297 of 539\n",
      "298 of 539\n",
      "299 of 539\n",
      "300 of 539, Run time : 46.52 minutes\n",
      "301 of 539\n",
      "302 of 539\n",
      "303 of 539\n",
      "304 of 539\n",
      "305 of 539\n",
      "306 of 539\n",
      "307 of 539\n",
      "308 of 539\n",
      "309 of 539\n",
      "310 of 539\n",
      "311 of 539\n",
      "312 of 539\n",
      "313 of 539\n",
      "314 of 539\n",
      "315 of 539\n",
      "316 of 539\n",
      "317 of 539\n",
      "318 of 539\n",
      "319 of 539\n",
      "320 of 539\n",
      "321 of 539\n",
      "322 of 539\n",
      "323 of 539\n",
      "324 of 539\n",
      "325 of 539\n",
      "326 of 539\n",
      "327 of 539\n",
      "328 of 539\n",
      "329 of 539\n",
      "330 of 539\n",
      "331 of 539\n",
      "332 of 539\n",
      "333 of 539\n",
      "334 of 539\n",
      "335 of 539\n",
      "336 of 539\n",
      "337 of 539\n",
      "338 of 539\n",
      "339 of 539\n",
      "340 of 539\n",
      "341 of 539\n",
      "342 of 539\n",
      "343 of 539\n",
      "344 of 539\n",
      "345 of 539\n",
      "346 of 539\n",
      "347 of 539\n",
      "348 of 539\n",
      "349 of 539\n",
      "350 of 539, Run time : 54.02 minutes\n",
      "351 of 539\n",
      "352 of 539\n",
      "353 of 539\n",
      "354 of 539\n",
      "Pause to rest. Run time : 54.48 minutes\n",
      "\n",
      "Scraping page :\n",
      "355 of 539\n",
      "356 of 539\n",
      "357 of 539\n",
      "358 of 539\n",
      "359 of 539\n",
      "360 of 539\n",
      "361 of 539\n",
      "362 of 539\n",
      "363 of 539\n",
      "364 of 539\n",
      "365 of 539\n",
      "366 of 539\n",
      "367 of 539\n",
      "368 of 539\n",
      "369 of 539\n",
      "Pause to rest. Run time : 56.27 minutes\n",
      "\n",
      "Scraping page :\n",
      "370 of 539\n",
      "371 of 539\n",
      "372 of 539\n",
      "373 of 539\n",
      "374 of 539\n",
      "375 of 539\n",
      "376 of 539\n",
      "377 of 539\n",
      "378 of 539\n",
      "379 of 539\n",
      "380 of 539\n",
      "381 of 539\n",
      "382 of 539\n",
      "383 of 539\n",
      "384 of 539\n",
      "385 of 539\n",
      "386 of 539\n",
      "387 of 539\n",
      "388 of 539\n",
      "389 of 539\n",
      "390 of 539\n",
      "391 of 539\n",
      "392 of 539\n",
      "393 of 539\n",
      "394 of 539\n",
      "395 of 539\n",
      "396 of 539\n",
      "397 of 539\n",
      "398 of 539\n",
      "399 of 539\n",
      "400 of 539, Run time : 60.23 minutes\n",
      "401 of 539\n",
      "402 of 539\n",
      "403 of 539\n",
      "404 of 539\n",
      "405 of 539\n",
      "406 of 539\n",
      "407 of 539\n",
      "408 of 539\n",
      "409 of 539\n",
      "410 of 539\n",
      "411 of 539\n",
      "412 of 539\n",
      "413 of 539\n",
      "414 of 539\n",
      "415 of 539\n",
      "416 of 539\n",
      "417 of 539\n",
      "418 of 539\n",
      "419 of 539\n",
      "420 of 539\n",
      "421 of 539\n",
      "422 of 539\n",
      "423 of 539\n",
      "424 of 539\n",
      "425 of 539\n",
      "Pause to rest. Run time : 63.45 minutes\n",
      "\n",
      "Scraping page :\n",
      "426 of 539\n",
      "427 of 539\n",
      "428 of 539\n",
      "429 of 539\n",
      "430 of 539\n",
      "431 of 539\n",
      "432 of 539\n",
      "433 of 539\n",
      "434 of 539\n",
      "435 of 539\n",
      "436 of 539\n",
      "437 of 539\n",
      "438 of 539\n",
      "439 of 539\n",
      "440 of 539\n",
      "441 of 539\n",
      "442 of 539\n",
      "443 of 539\n",
      "Pause to rest. Run time : 65.71 minutes\n",
      "\n",
      "Scraping page :\n",
      "444 of 539\n",
      "445 of 539\n",
      "446 of 539\n",
      "447 of 539\n",
      "448 of 539\n",
      "449 of 539\n",
      "450 of 539, Run time : 66.64 minutes\n",
      "451 of 539\n",
      "452 of 539\n",
      "453 of 539\n",
      "454 of 539\n",
      "455 of 539\n",
      "456 of 539\n",
      "457 of 539\n",
      "458 of 539\n",
      "459 of 539\n",
      "460 of 539\n",
      "461 of 539\n",
      "462 of 539\n",
      "463 of 539\n",
      "464 of 539\n",
      "465 of 539\n",
      "466 of 539\n",
      "467 of 539\n",
      "468 of 539\n",
      "469 of 539\n",
      "470 of 539\n",
      "471 of 539\n",
      "472 of 539\n",
      "473 of 539\n",
      "474 of 539\n",
      "475 of 539\n",
      "476 of 539\n",
      "477 of 539\n",
      "478 of 539\n",
      "479 of 539\n",
      "480 of 539\n",
      "481 of 539\n",
      "482 of 539\n",
      "483 of 539\n",
      "484 of 539\n",
      "485 of 539\n",
      "486 of 539\n",
      "487 of 539\n",
      "488 of 539\n",
      "489 of 539\n",
      "490 of 539\n",
      "491 of 539\n",
      "492 of 539\n",
      "493 of 539\n",
      "494 of 539\n",
      "495 of 539\n",
      "496 of 539\n",
      "Pause to rest. Run time : 72.39 minutes\n",
      "\n",
      "Scraping page :\n",
      "497 of 539\n",
      "498 of 539\n",
      "499 of 539\n",
      "500 of 539, Run time : 73.01 minutes\n",
      "501 of 539\n",
      "502 of 539\n",
      "503 of 539\n",
      "504 of 539\n",
      "505 of 539\n",
      "506 of 539\n",
      "507 of 539\n",
      "508 of 539\n",
      "509 of 539\n",
      "510 of 539\n",
      "511 of 539\n",
      "512 of 539\n",
      "513 of 539\n",
      "514 of 539\n",
      "515 of 539\n",
      "516 of 539\n",
      "517 of 539\n",
      "Pause to rest. Run time : 75.21 minutes\n",
      "\n",
      "Scraping page :\n",
      "518 of 539\n",
      "519 of 539\n",
      "520 of 539\n",
      "521 of 539\n",
      "522 of 539\n",
      "523 of 539\n",
      "524 of 539\n",
      "525 of 539\n",
      "526 of 539\n",
      "527 of 539\n",
      "528 of 539\n",
      "529 of 539\n",
      "530 of 539\n",
      "531 of 539\n",
      "532 of 539\n",
      "533 of 539\n",
      "534 of 539\n",
      "535 of 539\n",
      "536 of 539\n",
      "537 of 539\n",
      "538 of 539\n",
      "539 of 539\n",
      "\n",
      "Successfully scraped for Oracle interviews.\n",
      "Total duration : 78.69 minutes\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.glassdoor.sg/Interview/Oracle-Interview-Questions-E1737.htm' # Change URL to company you want\n",
    "next_url = None\n",
    "page = 1\n",
    "num = 0\n",
    "main_dict = []\n",
    "prevent = [37,71]\n",
    "max_page = 540            # Change the page number to the number of pages you want to web scrape\n",
    "start_time = time.time()\n",
    "\n",
    "print('Scraping page :')\n",
    "\n",
    "while page < max_page:\n",
    "    if next_url == None:\n",
    "        next_url = url    \n",
    "    \n",
    "    else:\n",
    "        next_url = 'https://www.glassdoor.com'+after\n",
    "    \n",
    "    if page % prevent[num] == 0:\n",
    "        print(f'Pause to rest. Run time : {round((time.time() - start_time)/60,2)} minutes\\n')\n",
    "        time.sleep(random.randint(3,5))\n",
    "        print('Scraping page :')\n",
    "        num = 1 - num\n",
    "    \n",
    "    driver.get(next_url)\n",
    "    time.sleep(random.randint(1,3))\n",
    "    \n",
    "    post = html.fromstring(driver.page_source)\n",
    "    get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    " \n",
    "    while len(get_id) < 10:\n",
    "        print(f'Refreshing page {page}...')\n",
    "        driver.get(next_url)\n",
    "        time.sleep(random.randint(2,4))\n",
    "        post = html.fromstring(driver.page_source)\n",
    "        get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    "\n",
    "    for i in range(len(get_id)):\n",
    "        \n",
    "        id_pos = get_id[i].attrib['id']\n",
    "        interview_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[1]/p[4]/text()')\n",
    "        question_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[2]/ul/li/span/text()')\n",
    "        offer_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[1]/div/div[2]/span/text()')\n",
    "        experience_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[2]/div/div[2]/span/text()')\n",
    "        difficulty_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[3]/div/div[2]/span/text()')\n",
    "        \n",
    "        page_frame = {}\n",
    "        \n",
    "        if len(interview_) == 1:\n",
    "            page_frame['interview'] = interview_[0]\n",
    "            \n",
    "        if len(question_) == 1:\n",
    "            page_frame['question'] = question_[0]\n",
    "        \n",
    "        if len(offer_) == 1:\n",
    "            page_frame['offer'] = offer_[0]\n",
    "\n",
    "        if len(experience_) == 1:\n",
    "            page_frame['experience'] = experience_[0]\n",
    "\n",
    "        if len(difficulty_) == 1:\n",
    "            page_frame['difficulty'] = difficulty_[0]\n",
    "        \n",
    "        main_dict.append(page_frame)\n",
    "\n",
    "    if page % 50 == 0:\n",
    "        print(f'{page} of {max_page-1}, Run time : {round((time.time() - start_time)/60,2)} minutes')\n",
    "        \n",
    "    else:\n",
    "        print(f'{page} of {max_page-1}')\n",
    "    \n",
    "    page+=1\n",
    "    after = post.xpath('//*[@id=\"FooterPageNav\"]/div[2]/ul/li[7]/a/@href')[0]\n",
    "    oracle_df = pd.DataFrame(main_dict)                                        # Change the data frame and csv name\n",
    "\n",
    "print(f'\\nSuccessfully scraped for Oracle interviews.\\nTotal duration : {round((time.time() - start_time)/60,2)} minutes')\n",
    "# Change the name of company you are scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page :\n",
      "1 of 348\n",
      "2 of 348\n",
      "3 of 348\n",
      "4 of 348\n",
      "5 of 348\n",
      "6 of 348\n",
      "7 of 348\n",
      "8 of 348\n",
      "9 of 348\n",
      "10 of 348\n",
      "11 of 348\n",
      "12 of 348\n",
      "13 of 348\n",
      "14 of 348\n",
      "15 of 348\n",
      "16 of 348\n",
      "17 of 348\n",
      "18 of 348\n",
      "19 of 348\n",
      "20 of 348\n",
      "21 of 348\n",
      "22 of 348\n",
      "23 of 348\n",
      "24 of 348\n",
      "25 of 348\n",
      "26 of 348\n",
      "27 of 348\n",
      "28 of 348\n",
      "29 of 348\n",
      "30 of 348\n",
      "31 of 348\n",
      "32 of 348\n",
      "33 of 348\n",
      "34 of 348\n",
      "35 of 348\n",
      "36 of 348\n",
      "Pause to rest. Run time : 4.82 minutes\n",
      "\n",
      "Scraping page :\n",
      "37 of 348\n",
      "38 of 348\n",
      "39 of 348\n",
      "40 of 348\n",
      "41 of 348\n",
      "42 of 348\n",
      "43 of 348\n",
      "44 of 348\n",
      "45 of 348\n",
      "46 of 348\n",
      "47 of 348\n",
      "48 of 348\n",
      "49 of 348\n",
      "50 of 348, Run time : 6.82 minutes\n",
      "51 of 348\n",
      "52 of 348\n",
      "53 of 348\n",
      "54 of 348\n",
      "55 of 348\n",
      "56 of 348\n",
      "57 of 348\n",
      "58 of 348\n",
      "59 of 348\n",
      "60 of 348\n",
      "61 of 348\n",
      "62 of 348\n",
      "63 of 348\n",
      "64 of 348\n",
      "65 of 348\n",
      "66 of 348\n",
      "67 of 348\n",
      "68 of 348\n",
      "69 of 348\n",
      "70 of 348\n",
      "Pause to rest. Run time : 9.46 minutes\n",
      "\n",
      "Scraping page :\n",
      "71 of 348\n",
      "72 of 348\n",
      "73 of 348\n",
      "Pause to rest. Run time : 9.88 minutes\n",
      "\n",
      "Scraping page :\n",
      "74 of 348\n",
      "75 of 348\n",
      "76 of 348\n",
      "77 of 348\n",
      "78 of 348\n",
      "79 of 348\n",
      "80 of 348\n",
      "81 of 348\n",
      "82 of 348\n",
      "83 of 348\n",
      "84 of 348\n",
      "85 of 348\n",
      "86 of 348\n",
      "87 of 348\n",
      "88 of 348\n",
      "89 of 348\n",
      "90 of 348\n",
      "91 of 348\n",
      "92 of 348\n",
      "93 of 348\n",
      "94 of 348\n",
      "95 of 348\n",
      "96 of 348\n",
      "97 of 348\n",
      "98 of 348\n",
      "99 of 348\n",
      "100 of 348, Run time : 13.3 minutes\n",
      "101 of 348\n",
      "102 of 348\n",
      "103 of 348\n",
      "104 of 348\n",
      "105 of 348\n",
      "106 of 348\n",
      "107 of 348\n",
      "108 of 348\n",
      "109 of 348\n",
      "110 of 348\n",
      "111 of 348\n",
      "112 of 348\n",
      "113 of 348\n",
      "114 of 348\n",
      "115 of 348\n",
      "116 of 348\n",
      "117 of 348\n",
      "118 of 348\n",
      "119 of 348\n",
      "120 of 348\n",
      "121 of 348\n",
      "122 of 348\n",
      "123 of 348\n",
      "124 of 348\n",
      "125 of 348\n",
      "126 of 348\n",
      "127 of 348\n",
      "128 of 348\n",
      "129 of 348\n",
      "130 of 348\n",
      "131 of 348\n",
      "132 of 348\n",
      "133 of 348\n",
      "134 of 348\n",
      "135 of 348\n",
      "136 of 348\n",
      "137 of 348\n",
      "138 of 348\n",
      "139 of 348\n",
      "140 of 348\n",
      "141 of 348\n",
      "Pause to rest. Run time : 18.88 minutes\n",
      "\n",
      "Scraping page :\n",
      "142 of 348\n",
      "143 of 348\n",
      "144 of 348\n",
      "145 of 348\n",
      "146 of 348\n",
      "147 of 348\n",
      "Pause to rest. Run time : 19.7 minutes\n",
      "\n",
      "Scraping page :\n",
      "148 of 348\n",
      "149 of 348\n",
      "150 of 348, Run time : 20.17 minutes\n",
      "151 of 348\n",
      "152 of 348\n",
      "153 of 348\n",
      "154 of 348\n",
      "155 of 348\n",
      "156 of 348\n",
      "157 of 348\n",
      "158 of 348\n",
      "159 of 348\n",
      "160 of 348\n",
      "161 of 348\n",
      "162 of 348\n",
      "163 of 348\n",
      "164 of 348\n",
      "165 of 348\n",
      "166 of 348\n",
      "167 of 348\n",
      "168 of 348\n",
      "169 of 348\n",
      "170 of 348\n",
      "171 of 348\n",
      "172 of 348\n",
      "173 of 348\n",
      "174 of 348\n",
      "175 of 348\n",
      "176 of 348\n",
      "177 of 348\n",
      "178 of 348\n",
      "179 of 348\n",
      "180 of 348\n",
      "181 of 348\n",
      "182 of 348\n",
      "183 of 348\n",
      "184 of 348\n",
      "185 of 348\n",
      "186 of 348\n",
      "187 of 348\n",
      "188 of 348\n",
      "189 of 348\n",
      "190 of 348\n",
      "191 of 348\n",
      "192 of 348\n",
      "193 of 348\n",
      "194 of 348\n",
      "195 of 348\n",
      "196 of 348\n",
      "197 of 348\n",
      "198 of 348\n",
      "199 of 348\n",
      "200 of 348, Run time : 26.75 minutes\n",
      "201 of 348\n",
      "202 of 348\n",
      "203 of 348\n",
      "204 of 348\n",
      "205 of 348\n",
      "206 of 348\n",
      "207 of 348\n",
      "208 of 348\n",
      "209 of 348\n",
      "210 of 348\n",
      "211 of 348\n",
      "212 of 348\n",
      "Pause to rest. Run time : 29.43 minutes\n",
      "\n",
      "Scraping page :\n",
      "213 of 348\n",
      "214 of 348\n",
      "215 of 348\n",
      "216 of 348\n",
      "217 of 348\n",
      "218 of 348\n",
      "219 of 348\n",
      "220 of 348\n",
      "221 of 348\n",
      "Pause to rest. Run time : 31.16 minutes\n",
      "\n",
      "Scraping page :\n",
      "222 of 348\n",
      "223 of 348\n",
      "224 of 348\n",
      "225 of 348\n",
      "226 of 348\n",
      "227 of 348\n",
      "228 of 348\n",
      "229 of 348\n",
      "230 of 348\n",
      "231 of 348\n",
      "232 of 348\n",
      "233 of 348\n",
      "234 of 348\n",
      "235 of 348\n",
      "236 of 348\n",
      "237 of 348\n",
      "238 of 348\n",
      "239 of 348\n",
      "240 of 348\n",
      "241 of 348\n",
      "242 of 348\n",
      "243 of 348\n",
      "244 of 348\n",
      "245 of 348\n",
      "246 of 348\n",
      "247 of 348\n",
      "248 of 348\n",
      "249 of 348\n",
      "250 of 348, Run time : 35.54 minutes\n",
      "251 of 348\n",
      "252 of 348\n",
      "253 of 348\n",
      "254 of 348\n",
      "255 of 348\n",
      "256 of 348\n",
      "257 of 348\n",
      "258 of 348\n",
      "259 of 348\n",
      "260 of 348\n",
      "261 of 348\n",
      "262 of 348\n",
      "263 of 348\n",
      "264 of 348\n",
      "265 of 348\n",
      "266 of 348\n",
      "267 of 348\n",
      "268 of 348\n",
      "269 of 348\n",
      "270 of 348\n",
      "271 of 348\n",
      "272 of 348\n",
      "273 of 348\n",
      "274 of 348\n",
      "275 of 348\n",
      "276 of 348\n",
      "277 of 348\n",
      "278 of 348\n",
      "279 of 348\n",
      "280 of 348\n",
      "281 of 348\n",
      "282 of 348\n",
      "283 of 348\n",
      "Pause to rest. Run time : 40.33 minutes\n",
      "\n",
      "Scraping page :\n",
      "284 of 348\n",
      "285 of 348\n",
      "286 of 348\n",
      "287 of 348\n",
      "288 of 348\n",
      "289 of 348\n",
      "290 of 348\n",
      "291 of 348\n",
      "292 of 348\n",
      "293 of 348\n",
      "294 of 348\n",
      "295 of 348\n",
      "Pause to rest. Run time : 41.83 minutes\n",
      "\n",
      "Scraping page :\n",
      "296 of 348\n",
      "297 of 348\n",
      "298 of 348\n",
      "299 of 348\n",
      "300 of 348, Run time : 42.58 minutes\n",
      "301 of 348\n",
      "302 of 348\n",
      "303 of 348\n",
      "304 of 348\n",
      "305 of 348\n",
      "306 of 348\n",
      "307 of 348\n",
      "308 of 348\n",
      "309 of 348\n",
      "310 of 348\n",
      "311 of 348\n",
      "312 of 348\n",
      "313 of 348\n",
      "314 of 348\n",
      "315 of 348\n",
      "316 of 348\n",
      "317 of 348\n",
      "318 of 348\n",
      "319 of 348\n",
      "320 of 348\n",
      "321 of 348\n",
      "322 of 348\n",
      "323 of 348\n",
      "324 of 348\n",
      "325 of 348\n",
      "326 of 348\n",
      "327 of 348\n",
      "328 of 348\n",
      "329 of 348\n",
      "330 of 348\n",
      "331 of 348\n",
      "332 of 348\n",
      "333 of 348\n",
      "334 of 348\n",
      "335 of 348\n",
      "336 of 348\n",
      "337 of 348\n",
      "338 of 348\n",
      "339 of 348\n",
      "340 of 348\n",
      "341 of 348\n",
      "342 of 348\n",
      "343 of 348\n",
      "344 of 348\n",
      "345 of 348\n",
      "346 of 348\n",
      "347 of 348\n",
      "348 of 348\n",
      "\n",
      "Successfully scraped for Uber interviews.\n",
      "Total duration : 48.92 minutes\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.glassdoor.sg/Interview/Uber-Interview-Questions-E575263.htm' # Change URL to company you want\n",
    "next_url = None\n",
    "page = 1\n",
    "num = 0\n",
    "main_dict = []\n",
    "prevent = [37,71]\n",
    "max_page = 349            # Change the page number to the number of pages you want to web scrape\n",
    "start_time = time.time()\n",
    "\n",
    "print('Scraping page :')\n",
    "\n",
    "while page < max_page:\n",
    "    if next_url == None:\n",
    "        next_url = url    \n",
    "    \n",
    "    else:\n",
    "        next_url = 'https://www.glassdoor.com'+after\n",
    "    \n",
    "    if page % prevent[num] == 0:\n",
    "        print(f'Pause to rest. Run time : {round((time.time() - start_time)/60,2)} minutes\\n')\n",
    "        time.sleep(random.randint(3,5))\n",
    "        print('Scraping page :')\n",
    "        num = 1 - num\n",
    "    \n",
    "    driver.get(next_url)\n",
    "    time.sleep(random.randint(1,3))\n",
    "    \n",
    "    post = html.fromstring(driver.page_source)\n",
    "    get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    " \n",
    "    while len(get_id) < 10:\n",
    "        print(f'Refreshing page {page}...')\n",
    "        driver.get(next_url)\n",
    "        time.sleep(random.randint(2,4))\n",
    "        post = html.fromstring(driver.page_source)\n",
    "        get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    "\n",
    "    for i in range(len(get_id)):\n",
    "        \n",
    "        id_pos = get_id[i].attrib['id']\n",
    "        interview_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[1]/p[4]/text()')\n",
    "        question_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[2]/ul/li/span/text()')\n",
    "        offer_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[1]/div/div[2]/span/text()')\n",
    "        experience_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[2]/div/div[2]/span/text()')\n",
    "        difficulty_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[3]/div/div[2]/span/text()')\n",
    "        \n",
    "        page_frame = {}\n",
    "        \n",
    "        if len(interview_) == 1:\n",
    "            page_frame['interview'] = interview_[0]\n",
    "            \n",
    "        if len(question_) == 1:\n",
    "            page_frame['question'] = question_[0]\n",
    "        \n",
    "        if len(offer_) == 1:\n",
    "            page_frame['offer'] = offer_[0]\n",
    "\n",
    "        if len(experience_) == 1:\n",
    "            page_frame['experience'] = experience_[0]\n",
    "\n",
    "        if len(difficulty_) == 1:\n",
    "            page_frame['difficulty'] = difficulty_[0]\n",
    "        \n",
    "        main_dict.append(page_frame)\n",
    "\n",
    "    if page % 50 == 0:\n",
    "        print(f'{page} of {max_page-1}, Run time : {round((time.time() - start_time)/60,2)} minutes')\n",
    "        \n",
    "    else:\n",
    "        print(f'{page} of {max_page-1}')\n",
    "    \n",
    "    page+=1\n",
    "    after = post.xpath('//*[@id=\"FooterPageNav\"]/div[2]/ul/li[7]/a/@href')[0]\n",
    "    uber_df = pd.DataFrame(main_dict)                                        # Change the data frame and csv name\n",
    "\n",
    "print(f'\\nSuccessfully scraped for Uber interviews.\\nTotal duration : {round((time.time() - start_time)/60,2)} minutes')\n",
    "# Change the name of company you are scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page :\n",
      "1 of 101\n",
      "2 of 101\n",
      "3 of 101\n",
      "4 of 101\n",
      "5 of 101\n",
      "6 of 101\n",
      "7 of 101\n",
      "8 of 101\n",
      "9 of 101\n",
      "10 of 101\n",
      "11 of 101\n",
      "12 of 101\n",
      "13 of 101\n",
      "14 of 101\n",
      "15 of 101\n",
      "16 of 101\n",
      "17 of 101\n",
      "18 of 101\n",
      "19 of 101\n",
      "20 of 101\n",
      "21 of 101\n",
      "22 of 101\n",
      "23 of 101\n",
      "24 of 101\n",
      "25 of 101\n",
      "26 of 101\n",
      "27 of 101\n",
      "28 of 101\n",
      "29 of 101\n",
      "30 of 101\n",
      "31 of 101\n",
      "32 of 101\n",
      "33 of 101\n",
      "34 of 101\n",
      "35 of 101\n",
      "36 of 101\n",
      "Pause to rest. Run time : 5.38 minutes\n",
      "\n",
      "Scraping page :\n",
      "37 of 101\n",
      "38 of 101\n",
      "39 of 101\n",
      "40 of 101\n",
      "41 of 101\n",
      "42 of 101\n",
      "43 of 101\n",
      "44 of 101\n",
      "45 of 101\n",
      "46 of 101\n",
      "47 of 101\n",
      "48 of 101\n",
      "49 of 101\n",
      "50 of 101, Run time : 7.1 minutes\n",
      "51 of 101\n",
      "52 of 101\n",
      "53 of 101\n",
      "54 of 101\n",
      "55 of 101\n",
      "56 of 101\n",
      "57 of 101\n",
      "58 of 101\n",
      "59 of 101\n",
      "60 of 101\n",
      "61 of 101\n",
      "62 of 101\n",
      "63 of 101\n",
      "64 of 101\n",
      "65 of 101\n",
      "66 of 101\n",
      "67 of 101\n",
      "68 of 101\n",
      "69 of 101\n",
      "70 of 101\n",
      "Pause to rest. Run time : 9.56 minutes\n",
      "\n",
      "Scraping page :\n",
      "71 of 101\n",
      "72 of 101\n",
      "73 of 101\n",
      "Pause to rest. Run time : 9.99 minutes\n",
      "\n",
      "Scraping page :\n",
      "74 of 101\n",
      "75 of 101\n",
      "76 of 101\n",
      "77 of 101\n",
      "78 of 101\n",
      "79 of 101\n",
      "80 of 101\n",
      "81 of 101\n",
      "82 of 101\n",
      "83 of 101\n",
      "84 of 101\n",
      "85 of 101\n",
      "86 of 101\n",
      "87 of 101\n",
      "88 of 101\n",
      "89 of 101\n",
      "90 of 101\n",
      "91 of 101\n",
      "92 of 101\n",
      "93 of 101\n",
      "94 of 101\n",
      "95 of 101\n",
      "96 of 101\n",
      "97 of 101\n",
      "98 of 101\n",
      "99 of 101\n",
      "100 of 101, Run time : 13.6 minutes\n",
      "101 of 101\n",
      "\n",
      "Successfully scraped for twitter interviews.\n",
      "Total duration : 13.72 minutes\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.glassdoor.sg/Interview/Twitter-Interview-Questions-E100569.htm' # Change URL to company you want\n",
    "next_url = None\n",
    "page = 1\n",
    "num = 0\n",
    "main_dict = []\n",
    "prevent = [37,71]\n",
    "max_page = 102            # Change the page number to the number of pages you want to web scrape\n",
    "start_time = time.time()\n",
    "\n",
    "print('Scraping page :')\n",
    "\n",
    "while page < max_page:\n",
    "    if next_url == None:\n",
    "        next_url = url    \n",
    "    \n",
    "    else:\n",
    "        next_url = 'https://www.glassdoor.com'+after\n",
    "    \n",
    "    if page % prevent[num] == 0:\n",
    "        print(f'Pause to rest. Run time : {round((time.time() - start_time)/60,2)} minutes\\n')\n",
    "        time.sleep(random.randint(3,5))\n",
    "        print('Scraping page :')\n",
    "        num = 1 - num\n",
    "    \n",
    "    driver.get(next_url)\n",
    "    time.sleep(random.randint(1,3))\n",
    "    \n",
    "    post = html.fromstring(driver.page_source)\n",
    "    get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    " \n",
    "    while len(get_id) < 10:\n",
    "        print(f'Refreshing page {page}...')\n",
    "        driver.get(next_url)\n",
    "        time.sleep(random.randint(2,4))\n",
    "        post = html.fromstring(driver.page_source)\n",
    "        get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    "\n",
    "    for i in range(len(get_id)):\n",
    "        \n",
    "        id_pos = get_id[i].attrib['id']\n",
    "        interview_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[1]/p[4]/text()')\n",
    "        question_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[2]/ul/li/span/text()')\n",
    "        offer_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[1]/div/div[2]/span/text()')\n",
    "        experience_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[2]/div/div[2]/span/text()')\n",
    "        difficulty_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[3]/div/div[2]/span/text()')\n",
    "        \n",
    "        page_frame = {}\n",
    "        \n",
    "        if len(interview_) == 1:\n",
    "            page_frame['interview'] = interview_[0]\n",
    "            \n",
    "        if len(question_) == 1:\n",
    "            page_frame['question'] = question_[0]\n",
    "        \n",
    "        if len(offer_) == 1:\n",
    "            page_frame['offer'] = offer_[0]\n",
    "\n",
    "        if len(experience_) == 1:\n",
    "            page_frame['experience'] = experience_[0]\n",
    "\n",
    "        if len(difficulty_) == 1:\n",
    "            page_frame['difficulty'] = difficulty_[0]\n",
    "        \n",
    "        main_dict.append(page_frame)\n",
    "\n",
    "    if page % 50 == 0:\n",
    "        print(f'{page} of {max_page-1}, Run time : {round((time.time() - start_time)/60,2)} minutes')\n",
    "        \n",
    "    else:\n",
    "        print(f'{page} of {max_page-1}')\n",
    "    \n",
    "    page+=1\n",
    "    after = post.xpath('//*[@id=\"FooterPageNav\"]/div[2]/ul/li[7]/a/@href')[0]\n",
    "    twitter_df = pd.DataFrame(main_dict)                                        # Change the data frame and csv name\n",
    "\n",
    "print(f'\\nSuccessfully scraped for twitter interviews.\\nTotal duration : {round((time.time() - start_time)/60,2)} minutes')\n",
    "# Change the name of company you are scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page :\n",
      "1 of 117\n",
      "2 of 117\n",
      "3 of 117\n",
      "4 of 117\n",
      "5 of 117\n",
      "6 of 117\n",
      "7 of 117\n",
      "8 of 117\n",
      "9 of 117\n",
      "10 of 117\n",
      "11 of 117\n",
      "12 of 117\n",
      "13 of 117\n",
      "14 of 117\n",
      "15 of 117\n",
      "16 of 117\n",
      "17 of 117\n",
      "18 of 117\n",
      "19 of 117\n",
      "20 of 117\n",
      "21 of 117\n",
      "22 of 117\n",
      "23 of 117\n",
      "24 of 117\n",
      "25 of 117\n",
      "26 of 117\n",
      "27 of 117\n",
      "28 of 117\n",
      "29 of 117\n",
      "30 of 117\n",
      "31 of 117\n",
      "32 of 117\n",
      "33 of 117\n",
      "34 of 117\n",
      "35 of 117\n",
      "36 of 117\n",
      "Pause to rest. Run time : 4.13 minutes\n",
      "\n",
      "Scraping page :\n",
      "37 of 117\n",
      "38 of 117\n",
      "39 of 117\n",
      "40 of 117\n",
      "41 of 117\n",
      "42 of 117\n",
      "43 of 117\n",
      "44 of 117\n",
      "45 of 117\n",
      "46 of 117\n",
      "47 of 117\n",
      "48 of 117\n",
      "49 of 117\n",
      "50 of 117, Run time : 5.77 minutes\n",
      "51 of 117\n",
      "52 of 117\n",
      "53 of 117\n",
      "54 of 117\n",
      "55 of 117\n",
      "56 of 117\n",
      "57 of 117\n",
      "58 of 117\n",
      "59 of 117\n",
      "60 of 117\n",
      "61 of 117\n",
      "62 of 117\n",
      "63 of 117\n",
      "64 of 117\n",
      "65 of 117\n",
      "66 of 117\n",
      "67 of 117\n",
      "68 of 117\n",
      "69 of 117\n",
      "70 of 117\n",
      "Pause to rest. Run time : 8.02 minutes\n",
      "\n",
      "Scraping page :\n",
      "71 of 117\n",
      "72 of 117\n",
      "73 of 117\n",
      "Pause to rest. Run time : 8.48 minutes\n",
      "\n",
      "Scraping page :\n",
      "74 of 117\n",
      "75 of 117\n",
      "76 of 117\n",
      "77 of 117\n",
      "78 of 117\n",
      "79 of 117\n",
      "80 of 117\n",
      "81 of 117\n",
      "82 of 117\n",
      "83 of 117\n",
      "84 of 117\n",
      "85 of 117\n",
      "86 of 117\n",
      "87 of 117\n",
      "88 of 117\n",
      "89 of 117\n",
      "90 of 117\n",
      "91 of 117\n",
      "92 of 117\n",
      "93 of 117\n",
      "94 of 117\n",
      "95 of 117\n",
      "96 of 117\n",
      "97 of 117\n",
      "98 of 117\n",
      "99 of 117\n",
      "100 of 117, Run time : 11.67 minutes\n",
      "101 of 117\n",
      "102 of 117\n",
      "103 of 117\n",
      "104 of 117\n",
      "105 of 117\n",
      "106 of 117\n",
      "107 of 117\n",
      "108 of 117\n",
      "109 of 117\n",
      "110 of 117\n",
      "111 of 117\n",
      "112 of 117\n",
      "113 of 117\n",
      "114 of 117\n",
      "115 of 117\n",
      "116 of 117\n",
      "117 of 117\n",
      "\n",
      "Successfully scraped for Lyft interviews.\n",
      "Total duration : 13.55 minutes\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.glassdoor.sg/Interview/Lyft-Interview-Questions-E700614.htm' # Change URL to company you want\n",
    "next_url = None\n",
    "page = 1\n",
    "num = 0\n",
    "main_dict = []\n",
    "prevent = [37,71]\n",
    "max_page = 118            # Change the page number to the number of pages you want to web scrape\n",
    "start_time = time.time()\n",
    "\n",
    "print('Scraping page :')\n",
    "\n",
    "while page < max_page:\n",
    "    if next_url == None:\n",
    "        next_url = url    \n",
    "    \n",
    "    else:\n",
    "        next_url = 'https://www.glassdoor.com'+after\n",
    "    \n",
    "    if page % prevent[num] == 0:\n",
    "        print(f'Pause to rest. Run time : {round((time.time() - start_time)/60,2)} minutes\\n')\n",
    "        time.sleep(random.randint(3,5))\n",
    "        print('Scraping page :')\n",
    "        num = 1 - num\n",
    "    \n",
    "    driver.get(next_url)\n",
    "    time.sleep(random.randint(1,3))\n",
    "    \n",
    "    post = html.fromstring(driver.page_source)\n",
    "    get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    " \n",
    "    while len(get_id) < 10:\n",
    "        print(f'Refreshing page {page}...')\n",
    "        driver.get(next_url)\n",
    "        time.sleep(random.randint(2,4))\n",
    "        post = html.fromstring(driver.page_source)\n",
    "        get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    "\n",
    "    for i in range(len(get_id)):\n",
    "        \n",
    "        id_pos = get_id[i].attrib['id']\n",
    "        interview_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[1]/p[4]/text()')\n",
    "        question_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[2]/ul/li/span/text()')\n",
    "        offer_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[1]/div/div[2]/span/text()')\n",
    "        experience_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[2]/div/div[2]/span/text()')\n",
    "        difficulty_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[3]/div/div[2]/span/text()')\n",
    "        \n",
    "        page_frame = {}\n",
    "        \n",
    "        if len(interview_) == 1:\n",
    "            page_frame['interview'] = interview_[0]\n",
    "            \n",
    "        if len(question_) == 1:\n",
    "            page_frame['question'] = question_[0]\n",
    "        \n",
    "        if len(offer_) == 1:\n",
    "            page_frame['offer'] = offer_[0]\n",
    "\n",
    "        if len(experience_) == 1:\n",
    "            page_frame['experience'] = experience_[0]\n",
    "\n",
    "        if len(difficulty_) == 1:\n",
    "            page_frame['difficulty'] = difficulty_[0]\n",
    "        \n",
    "        main_dict.append(page_frame)\n",
    "\n",
    "    if page % 50 == 0:\n",
    "        print(f'{page} of {max_page-1}, Run time : {round((time.time() - start_time)/60,2)} minutes')\n",
    "        \n",
    "    else:\n",
    "        print(f'{page} of {max_page-1}')\n",
    "    \n",
    "    page+=1\n",
    "    after = post.xpath('//*[@id=\"FooterPageNav\"]/div[2]/ul/li[7]/a/@href')[0]\n",
    "    lyft_df = pd.DataFrame(main_dict)                                        # Change the data frame and csv name\n",
    "\n",
    "print(f'\\nSuccessfully scraped for Lyft interviews.\\nTotal duration : {round((time.time() - start_time)/60,2)} minutes')\n",
    "# Change the name of company you are scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page :\n",
      "1 of 28\n",
      "2 of 28\n",
      "3 of 28\n",
      "4 of 28\n",
      "5 of 28\n",
      "6 of 28\n",
      "7 of 28\n",
      "8 of 28\n",
      "9 of 28\n",
      "10 of 28\n",
      "11 of 28\n",
      "12 of 28\n",
      "13 of 28\n",
      "14 of 28\n",
      "15 of 28\n",
      "16 of 28\n",
      "17 of 28\n",
      "18 of 28\n",
      "19 of 28\n",
      "20 of 28\n",
      "21 of 28\n",
      "22 of 28\n",
      "23 of 28\n",
      "24 of 28\n",
      "25 of 28\n",
      "26 of 28\n",
      "27 of 28\n",
      "28 of 28\n",
      "\n",
      "Successfully scraped for pinterest interviews.\n",
      "Total duration : 3.16 minutes\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.glassdoor.sg/Interview/Pinterest-Interview-Questions-E503467.htm' # Change URL to company you want\n",
    "next_url = None\n",
    "page = 1\n",
    "num = 0\n",
    "main_dict = []\n",
    "prevent = [37,71]\n",
    "max_page = 29            # Change the page number to the number of pages you want to web scrape\n",
    "start_time = time.time()\n",
    "\n",
    "print('Scraping page :')\n",
    "\n",
    "while page < max_page:\n",
    "    if next_url == None:\n",
    "        next_url = url    \n",
    "    \n",
    "    else:\n",
    "        next_url = 'https://www.glassdoor.com'+after\n",
    "    \n",
    "    if page % prevent[num] == 0:\n",
    "        print(f'Pause to rest. Run time : {round((time.time() - start_time)/60,2)} minutes\\n')\n",
    "        time.sleep(random.randint(3,5))\n",
    "        print('Scraping page :')\n",
    "        num = 1 - num\n",
    "    \n",
    "    driver.get(next_url)\n",
    "    time.sleep(random.randint(1,3))\n",
    "    \n",
    "    post = html.fromstring(driver.page_source)\n",
    "    get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    " \n",
    "    while len(get_id) < 10:\n",
    "        print(f'Refreshing page {page}...')\n",
    "        driver.get(next_url)\n",
    "        time.sleep(random.randint(2,4))\n",
    "        post = html.fromstring(driver.page_source)\n",
    "        get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    "\n",
    "    for i in range(len(get_id)):\n",
    "        \n",
    "        id_pos = get_id[i].attrib['id']\n",
    "        interview_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[1]/p[4]/text()')\n",
    "        question_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[2]/ul/li/span/text()')\n",
    "        offer_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[1]/div/div[2]/span/text()')\n",
    "        experience_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[2]/div/div[2]/span/text()')\n",
    "        difficulty_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[3]/div/div[2]/span/text()')\n",
    "        \n",
    "        page_frame = {}\n",
    "        \n",
    "        if len(interview_) == 1:\n",
    "            page_frame['interview'] = interview_[0]\n",
    "            \n",
    "        if len(question_) == 1:\n",
    "            page_frame['question'] = question_[0]\n",
    "        \n",
    "        if len(offer_) == 1:\n",
    "            page_frame['offer'] = offer_[0]\n",
    "\n",
    "        if len(experience_) == 1:\n",
    "            page_frame['experience'] = experience_[0]\n",
    "\n",
    "        if len(difficulty_) == 1:\n",
    "            page_frame['difficulty'] = difficulty_[0]\n",
    "        \n",
    "        main_dict.append(page_frame)\n",
    "\n",
    "    if page % 50 == 0:\n",
    "        print(f'{page} of {max_page-1}, Run time : {round((time.time() - start_time)/60,2)} minutes')\n",
    "        \n",
    "    else:\n",
    "        print(f'{page} of {max_page-1}')\n",
    "    \n",
    "    page+=1\n",
    "    after = post.xpath('//*[@id=\"FooterPageNav\"]/div[2]/ul/li[7]/a/@href')[0]\n",
    "    pinterest_df = pd.DataFrame(main_dict)                                        # Change the data frame and csv name\n",
    "\n",
    "print(f'\\nSuccessfully scraped for pinterest interviews.\\nTotal duration : {round((time.time() - start_time)/60,2)} minutes')\n",
    "# Change the name of company you are scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page :\n",
      "1 of 93\n",
      "2 of 93\n",
      "3 of 93\n",
      "4 of 93\n",
      "5 of 93\n",
      "6 of 93\n",
      "7 of 93\n",
      "8 of 93\n",
      "9 of 93\n",
      "10 of 93\n",
      "11 of 93\n",
      "12 of 93\n",
      "13 of 93\n",
      "14 of 93\n",
      "15 of 93\n",
      "16 of 93\n",
      "17 of 93\n",
      "18 of 93\n",
      "19 of 93\n",
      "20 of 93\n",
      "21 of 93\n",
      "22 of 93\n",
      "23 of 93\n",
      "24 of 93\n",
      "25 of 93\n",
      "26 of 93\n",
      "27 of 93\n",
      "28 of 93\n",
      "29 of 93\n",
      "30 of 93\n",
      "31 of 93\n",
      "32 of 93\n",
      "33 of 93\n",
      "34 of 93\n",
      "35 of 93\n",
      "36 of 93\n",
      "Pause to rest. Run time : 4.42 minutes\n",
      "\n",
      "Scraping page :\n",
      "37 of 93\n",
      "38 of 93\n",
      "39 of 93\n",
      "40 of 93\n",
      "41 of 93\n",
      "42 of 93\n",
      "43 of 93\n",
      "44 of 93\n",
      "45 of 93\n",
      "46 of 93\n",
      "47 of 93\n",
      "48 of 93\n",
      "49 of 93\n",
      "50 of 93, Run time : 7.71 minutes\n",
      "51 of 93\n",
      "52 of 93\n",
      "53 of 93\n",
      "54 of 93\n",
      "55 of 93\n",
      "56 of 93\n",
      "57 of 93\n",
      "58 of 93\n",
      "59 of 93\n",
      "60 of 93\n",
      "61 of 93\n",
      "62 of 93\n",
      "63 of 93\n",
      "64 of 93\n",
      "65 of 93\n",
      "66 of 93\n",
      "67 of 93\n",
      "68 of 93\n",
      "69 of 93\n",
      "70 of 93\n",
      "Pause to rest. Run time : 12.3 minutes\n",
      "\n",
      "Scraping page :\n",
      "71 of 93\n",
      "72 of 93\n",
      "73 of 93\n",
      "Pause to rest. Run time : 12.99 minutes\n",
      "\n",
      "Scraping page :\n",
      "74 of 93\n",
      "75 of 93\n",
      "76 of 93\n",
      "77 of 93\n",
      "78 of 93\n",
      "79 of 93\n",
      "80 of 93\n",
      "81 of 93\n",
      "82 of 93\n",
      "83 of 93\n",
      "84 of 93\n",
      "85 of 93\n",
      "86 of 93\n",
      "87 of 93\n",
      "88 of 93\n",
      "89 of 93\n",
      "90 of 93\n",
      "91 of 93\n",
      "92 of 93\n",
      "93 of 93\n",
      "\n",
      "Successfully scraped for airbnb interviews.\n",
      "Total duration : 16.16 minutes\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.glassdoor.sg/Interview/Airbnb-Interview-Questions-E391850.htm' # Change URL to company you want\n",
    "next_url = None\n",
    "page = 1\n",
    "num = 0\n",
    "main_dict = []\n",
    "prevent = [37,71]\n",
    "max_page = 94            # Change the page number to the number of pages you want to web scrape\n",
    "start_time = time.time()\n",
    "\n",
    "print('Scraping page :')\n",
    "\n",
    "while page < max_page:\n",
    "    if next_url == None:\n",
    "        next_url = url    \n",
    "    \n",
    "    else:\n",
    "        next_url = 'https://www.glassdoor.com'+after\n",
    "    \n",
    "    if page % prevent[num] == 0:\n",
    "        print(f'Pause to rest. Run time : {round((time.time() - start_time)/60,2)} minutes\\n')\n",
    "        time.sleep(random.randint(3,5))\n",
    "        print('Scraping page :')\n",
    "        num = 1 - num\n",
    "    \n",
    "    driver.get(next_url)\n",
    "    time.sleep(random.randint(1,3))\n",
    "    \n",
    "    post = html.fromstring(driver.page_source)\n",
    "    get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    " \n",
    "    while len(get_id) < 10:\n",
    "        print(f'Refreshing page {page}...')\n",
    "        driver.get(next_url)\n",
    "        time.sleep(random.randint(2,4))\n",
    "        post = html.fromstring(driver.page_source)\n",
    "        get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    "\n",
    "    for i in range(len(get_id)):\n",
    "        \n",
    "        id_pos = get_id[i].attrib['id']\n",
    "        interview_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[1]/p[4]/text()')\n",
    "        question_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[2]/ul/li/span/text()')\n",
    "        offer_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[1]/div/div[2]/span/text()')\n",
    "        experience_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[2]/div/div[2]/span/text()')\n",
    "        difficulty_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[3]/div/div[2]/span/text()')\n",
    "        \n",
    "        page_frame = {}\n",
    "        \n",
    "        if len(interview_) == 1:\n",
    "            page_frame['interview'] = interview_[0]\n",
    "            \n",
    "        if len(question_) == 1:\n",
    "            page_frame['question'] = question_[0]\n",
    "        \n",
    "        if len(offer_) == 1:\n",
    "            page_frame['offer'] = offer_[0]\n",
    "\n",
    "        if len(experience_) == 1:\n",
    "            page_frame['experience'] = experience_[0]\n",
    "\n",
    "        if len(difficulty_) == 1:\n",
    "            page_frame['difficulty'] = difficulty_[0]\n",
    "        \n",
    "        main_dict.append(page_frame)\n",
    "\n",
    "    if page % 50 == 0:\n",
    "        print(f'{page} of {max_page-1}, Run time : {round((time.time() - start_time)/60,2)} minutes')\n",
    "        \n",
    "    else:\n",
    "        print(f'{page} of {max_page-1}')\n",
    "    \n",
    "    page+=1\n",
    "    after = post.xpath('//*[@id=\"FooterPageNav\"]/div[2]/ul/li[7]/a/@href')[0]\n",
    "    airbnb_df = pd.DataFrame(main_dict)                                        # Change the data frame and csv name\n",
    "\n",
    "print(f'\\nSuccessfully scraped for airbnb interviews.\\nTotal duration : {round((time.time() - start_time)/60,2)} minutes')\n",
    "# Change the name of company you are scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page :\n",
      "1 of 254\n",
      "2 of 254\n",
      "3 of 254\n",
      "4 of 254\n",
      "5 of 254\n",
      "6 of 254\n",
      "7 of 254\n",
      "8 of 254\n",
      "9 of 254\n",
      "10 of 254\n",
      "11 of 254\n",
      "12 of 254\n",
      "13 of 254\n",
      "14 of 254\n",
      "15 of 254\n",
      "16 of 254\n",
      "17 of 254\n",
      "18 of 254\n",
      "19 of 254\n",
      "20 of 254\n",
      "21 of 254\n",
      "22 of 254\n",
      "23 of 254\n",
      "24 of 254\n",
      "25 of 254\n",
      "26 of 254\n",
      "27 of 254\n",
      "28 of 254\n",
      "29 of 254\n",
      "30 of 254\n",
      "31 of 254\n",
      "32 of 254\n",
      "33 of 254\n",
      "34 of 254\n",
      "35 of 254\n",
      "36 of 254\n",
      "Pause to rest. Run time : 7.75 minutes\n",
      "\n",
      "Scraping page :\n",
      "37 of 254\n",
      "38 of 254\n",
      "39 of 254\n",
      "40 of 254\n",
      "41 of 254\n",
      "42 of 254\n",
      "43 of 254\n",
      "44 of 254\n",
      "45 of 254\n",
      "46 of 254\n",
      "47 of 254\n",
      "48 of 254\n",
      "49 of 254\n",
      "50 of 254, Run time : 9.97 minutes\n",
      "51 of 254\n",
      "52 of 254\n",
      "53 of 254\n",
      "54 of 254\n",
      "55 of 254\n",
      "56 of 254\n",
      "57 of 254\n",
      "58 of 254\n",
      "59 of 254\n",
      "60 of 254\n",
      "61 of 254\n",
      "62 of 254\n",
      "63 of 254\n",
      "64 of 254\n",
      "65 of 254\n",
      "66 of 254\n",
      "67 of 254\n",
      "68 of 254\n",
      "69 of 254\n",
      "70 of 254\n",
      "Pause to rest. Run time : 12.15 minutes\n",
      "\n",
      "Scraping page :\n",
      "71 of 254\n",
      "72 of 254\n",
      "73 of 254\n",
      "Pause to rest. Run time : 12.61 minutes\n",
      "\n",
      "Scraping page :\n",
      "74 of 254\n",
      "75 of 254\n",
      "76 of 254\n",
      "77 of 254\n",
      "78 of 254\n",
      "79 of 254\n",
      "80 of 254\n",
      "81 of 254\n",
      "82 of 254\n",
      "83 of 254\n",
      "84 of 254\n",
      "85 of 254\n",
      "86 of 254\n",
      "87 of 254\n",
      "88 of 254\n",
      "89 of 254\n",
      "90 of 254\n",
      "91 of 254\n",
      "92 of 254\n",
      "93 of 254\n",
      "94 of 254\n",
      "95 of 254\n",
      "96 of 254\n",
      "97 of 254\n",
      "98 of 254\n",
      "99 of 254\n",
      "100 of 254, Run time : 15.63 minutes\n",
      "101 of 254\n",
      "102 of 254\n",
      "103 of 254\n",
      "104 of 254\n",
      "105 of 254\n",
      "106 of 254\n",
      "107 of 254\n",
      "108 of 254\n",
      "109 of 254\n",
      "110 of 254\n",
      "111 of 254\n",
      "112 of 254\n",
      "113 of 254\n",
      "114 of 254\n",
      "115 of 254\n",
      "116 of 254\n",
      "117 of 254\n",
      "118 of 254\n",
      "119 of 254\n",
      "120 of 254\n",
      "121 of 254\n",
      "122 of 254\n",
      "123 of 254\n",
      "124 of 254\n",
      "125 of 254\n",
      "126 of 254\n",
      "127 of 254\n",
      "128 of 254\n",
      "129 of 254\n",
      "130 of 254\n",
      "131 of 254\n",
      "132 of 254\n",
      "133 of 254\n",
      "134 of 254\n",
      "135 of 254\n",
      "136 of 254\n",
      "137 of 254\n",
      "138 of 254\n",
      "139 of 254\n",
      "140 of 254\n",
      "141 of 254\n",
      "Pause to rest. Run time : 19.88 minutes\n",
      "\n",
      "Scraping page :\n",
      "142 of 254\n",
      "143 of 254\n",
      "144 of 254\n",
      "145 of 254\n",
      "146 of 254\n",
      "147 of 254\n",
      "Pause to rest. Run time : 20.56 minutes\n",
      "\n",
      "Scraping page :\n",
      "148 of 254\n",
      "149 of 254\n",
      "150 of 254, Run time : 20.96 minutes\n",
      "151 of 254\n",
      "152 of 254\n",
      "153 of 254\n",
      "154 of 254\n",
      "155 of 254\n",
      "156 of 254\n",
      "157 of 254\n",
      "158 of 254\n",
      "159 of 254\n",
      "160 of 254\n",
      "161 of 254\n",
      "162 of 254\n",
      "163 of 254\n",
      "164 of 254\n",
      "165 of 254\n",
      "166 of 254\n",
      "167 of 254\n",
      "168 of 254\n",
      "169 of 254\n",
      "170 of 254\n",
      "171 of 254\n",
      "172 of 254\n",
      "173 of 254\n",
      "174 of 254\n",
      "175 of 254\n",
      "176 of 254\n",
      "177 of 254\n",
      "178 of 254\n",
      "179 of 254\n",
      "180 of 254\n",
      "181 of 254\n",
      "182 of 254\n",
      "183 of 254\n",
      "184 of 254\n",
      "185 of 254\n",
      "186 of 254\n",
      "187 of 254\n",
      "188 of 254\n",
      "189 of 254\n",
      "190 of 254\n",
      "191 of 254\n",
      "192 of 254\n",
      "193 of 254\n",
      "194 of 254\n",
      "195 of 254\n",
      "196 of 254\n",
      "197 of 254\n",
      "198 of 254\n",
      "199 of 254\n",
      "200 of 254, Run time : 26.34 minutes\n",
      "201 of 254\n",
      "202 of 254\n",
      "203 of 254\n",
      "204 of 254\n",
      "205 of 254\n",
      "206 of 254\n",
      "207 of 254\n",
      "208 of 254\n",
      "209 of 254\n",
      "210 of 254\n",
      "211 of 254\n",
      "212 of 254\n",
      "Pause to rest. Run time : 27.84 minutes\n",
      "\n",
      "Scraping page :\n",
      "213 of 254\n",
      "214 of 254\n",
      "215 of 254\n",
      "216 of 254\n",
      "217 of 254\n",
      "218 of 254\n",
      "219 of 254\n",
      "220 of 254\n",
      "221 of 254\n",
      "Pause to rest. Run time : 28.88 minutes\n",
      "\n",
      "Scraping page :\n",
      "222 of 254\n",
      "223 of 254\n",
      "224 of 254\n",
      "225 of 254\n",
      "226 of 254\n",
      "227 of 254\n",
      "228 of 254\n",
      "229 of 254\n",
      "230 of 254\n",
      "231 of 254\n",
      "232 of 254\n",
      "233 of 254\n",
      "234 of 254\n",
      "235 of 254\n",
      "236 of 254\n",
      "237 of 254\n",
      "238 of 254\n",
      "239 of 254\n",
      "240 of 254\n",
      "241 of 254\n",
      "242 of 254\n",
      "243 of 254\n",
      "244 of 254\n",
      "245 of 254\n",
      "246 of 254\n",
      "247 of 254\n",
      "248 of 254\n",
      "249 of 254\n",
      "250 of 254, Run time : 32.08 minutes\n",
      "251 of 254\n",
      "252 of 254\n",
      "253 of 254\n",
      "254 of 254\n",
      "\n",
      "Successfully scraped for yelp interviews.\n",
      "Total duration : 32.5 minutes\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.glassdoor.sg/Interview/Yelp-Interview-Questions-E43314.htm' # Change URL to company you want\n",
    "next_url = None\n",
    "page = 1\n",
    "num = 0\n",
    "main_dict = []\n",
    "prevent = [37,71]\n",
    "max_page = 255            # Change the page number to the number of pages you want to web scrape\n",
    "start_time = time.time()\n",
    "\n",
    "print('Scraping page :')\n",
    "\n",
    "while page < max_page:\n",
    "    if next_url == None:\n",
    "        next_url = url    \n",
    "    \n",
    "    else:\n",
    "        next_url = 'https://www.glassdoor.com'+after\n",
    "    \n",
    "    if page % prevent[num] == 0:\n",
    "        print(f'Pause to rest. Run time : {round((time.time() - start_time)/60,2)} minutes\\n')\n",
    "        time.sleep(random.randint(3,5))\n",
    "        print('Scraping page :')\n",
    "        num = 1 - num\n",
    "    \n",
    "    driver.get(next_url)\n",
    "    time.sleep(random.randint(1,3))\n",
    "    \n",
    "    post = html.fromstring(driver.page_source)\n",
    "    get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    " \n",
    "    while len(get_id) < 10:\n",
    "        print(f'Refreshing page {page}...')\n",
    "        driver.get(next_url)\n",
    "        time.sleep(random.randint(2,4))\n",
    "        post = html.fromstring(driver.page_source)\n",
    "        get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    "\n",
    "    for i in range(len(get_id)):\n",
    "        \n",
    "        id_pos = get_id[i].attrib['id']\n",
    "        interview_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[1]/p[4]/text()')\n",
    "        question_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[2]/ul/li/span/text()')\n",
    "        offer_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[1]/div/div[2]/span/text()')\n",
    "        experience_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[2]/div/div[2]/span/text()')\n",
    "        difficulty_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[3]/div/div[2]/span/text()')\n",
    "        \n",
    "        page_frame = {}\n",
    "        \n",
    "        if len(interview_) == 1:\n",
    "            page_frame['interview'] = interview_[0]\n",
    "            \n",
    "        if len(question_) == 1:\n",
    "            page_frame['question'] = question_[0]\n",
    "        \n",
    "        if len(offer_) == 1:\n",
    "            page_frame['offer'] = offer_[0]\n",
    "\n",
    "        if len(experience_) == 1:\n",
    "            page_frame['experience'] = experience_[0]\n",
    "\n",
    "        if len(difficulty_) == 1:\n",
    "            page_frame['difficulty'] = difficulty_[0]\n",
    "        \n",
    "        main_dict.append(page_frame)\n",
    "\n",
    "    if page % 50 == 0:\n",
    "        print(f'{page} of {max_page-1}, Run time : {round((time.time() - start_time)/60,2)} minutes')\n",
    "        \n",
    "    else:\n",
    "        print(f'{page} of {max_page-1}')\n",
    "    \n",
    "    page+=1\n",
    "    after = post.xpath('//*[@id=\"FooterPageNav\"]/div[2]/ul/li[7]/a/@href')[0]\n",
    "    yelp_df = pd.DataFrame(main_dict)                                        # Change the data frame and csv name\n",
    "\n",
    "print(f'\\nSuccessfully scraped for yelp interviews.\\nTotal duration : {round((time.time() - start_time)/60,2)} minutes')\n",
    "# Change the name of company you are scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page :\n",
      "1 of 187\n",
      "2 of 187\n",
      "3 of 187\n",
      "4 of 187\n",
      "5 of 187\n",
      "6 of 187\n",
      "7 of 187\n",
      "8 of 187\n",
      "9 of 187\n",
      "10 of 187\n",
      "11 of 187\n",
      "12 of 187\n",
      "13 of 187\n",
      "14 of 187\n",
      "15 of 187\n",
      "16 of 187\n",
      "17 of 187\n",
      "18 of 187\n",
      "19 of 187\n",
      "20 of 187\n",
      "21 of 187\n",
      "22 of 187\n",
      "23 of 187\n",
      "24 of 187\n",
      "25 of 187\n",
      "26 of 187\n",
      "27 of 187\n",
      "28 of 187\n",
      "29 of 187\n",
      "30 of 187\n",
      "31 of 187\n",
      "32 of 187\n",
      "33 of 187\n",
      "34 of 187\n",
      "35 of 187\n",
      "36 of 187\n",
      "Pause to rest. Run time : 3.77 minutes\n",
      "\n",
      "Scraping page :\n",
      "37 of 187\n",
      "38 of 187\n",
      "39 of 187\n",
      "40 of 187\n",
      "41 of 187\n",
      "42 of 187\n",
      "43 of 187\n",
      "44 of 187\n",
      "45 of 187\n",
      "46 of 187\n",
      "47 of 187\n",
      "48 of 187\n",
      "49 of 187\n",
      "50 of 187, Run time : 5.2 minutes\n",
      "51 of 187\n",
      "52 of 187\n",
      "53 of 187\n",
      "54 of 187\n",
      "55 of 187\n",
      "56 of 187\n",
      "57 of 187\n",
      "58 of 187\n",
      "59 of 187\n",
      "60 of 187\n",
      "61 of 187\n",
      "62 of 187\n",
      "63 of 187\n",
      "64 of 187\n",
      "65 of 187\n",
      "66 of 187\n",
      "67 of 187\n",
      "68 of 187\n",
      "69 of 187\n",
      "70 of 187\n",
      "Pause to rest. Run time : 7.31 minutes\n",
      "\n",
      "Scraping page :\n",
      "71 of 187\n",
      "72 of 187\n",
      "73 of 187\n",
      "Pause to rest. Run time : 7.76 minutes\n",
      "\n",
      "Scraping page :\n",
      "74 of 187\n",
      "75 of 187\n",
      "76 of 187\n",
      "77 of 187\n",
      "78 of 187\n",
      "79 of 187\n",
      "80 of 187\n",
      "81 of 187\n",
      "82 of 187\n",
      "83 of 187\n",
      "84 of 187\n",
      "85 of 187\n",
      "86 of 187\n",
      "87 of 187\n",
      "88 of 187\n",
      "89 of 187\n",
      "90 of 187\n",
      "91 of 187\n",
      "92 of 187\n",
      "93 of 187\n",
      "94 of 187\n",
      "95 of 187\n",
      "96 of 187\n",
      "97 of 187\n",
      "98 of 187\n",
      "99 of 187\n",
      "100 of 187, Run time : 10.68 minutes\n",
      "101 of 187\n",
      "102 of 187\n",
      "103 of 187\n",
      "104 of 187\n",
      "105 of 187\n",
      "106 of 187\n",
      "107 of 187\n",
      "108 of 187\n",
      "109 of 187\n",
      "110 of 187\n",
      "111 of 187\n",
      "112 of 187\n",
      "113 of 187\n",
      "114 of 187\n",
      "115 of 187\n",
      "116 of 187\n",
      "117 of 187\n",
      "118 of 187\n",
      "119 of 187\n",
      "120 of 187\n",
      "121 of 187\n",
      "122 of 187\n",
      "123 of 187\n",
      "124 of 187\n",
      "125 of 187\n",
      "126 of 187\n",
      "127 of 187\n",
      "128 of 187\n",
      "129 of 187\n",
      "130 of 187\n",
      "131 of 187\n",
      "132 of 187\n",
      "133 of 187\n",
      "134 of 187\n",
      "135 of 187\n",
      "136 of 187\n",
      "137 of 187\n",
      "138 of 187\n",
      "139 of 187\n",
      "140 of 187\n",
      "141 of 187\n",
      "Pause to rest. Run time : 15.35 minutes\n",
      "\n",
      "Scraping page :\n",
      "142 of 187\n",
      "143 of 187\n",
      "144 of 187\n",
      "145 of 187\n",
      "146 of 187\n",
      "147 of 187\n",
      "Pause to rest. Run time : 16.08 minutes\n",
      "\n",
      "Scraping page :\n",
      "148 of 187\n",
      "149 of 187\n",
      "150 of 187, Run time : 16.45 minutes\n",
      "151 of 187\n",
      "152 of 187\n",
      "153 of 187\n",
      "154 of 187\n",
      "155 of 187\n",
      "156 of 187\n",
      "157 of 187\n",
      "158 of 187\n",
      "159 of 187\n",
      "160 of 187\n",
      "161 of 187\n",
      "162 of 187\n",
      "163 of 187\n",
      "164 of 187\n",
      "165 of 187\n",
      "166 of 187\n",
      "167 of 187\n",
      "168 of 187\n",
      "169 of 187\n",
      "170 of 187\n",
      "171 of 187\n",
      "172 of 187\n",
      "173 of 187\n",
      "174 of 187\n",
      "175 of 187\n",
      "176 of 187\n",
      "177 of 187\n",
      "178 of 187\n",
      "179 of 187\n",
      "180 of 187\n",
      "181 of 187\n",
      "182 of 187\n",
      "183 of 187\n",
      "184 of 187\n",
      "185 of 187\n",
      "186 of 187\n",
      "187 of 187\n",
      "\n",
      "Successfully scraped for bookingcom interviews.\n",
      "Total duration : 20.6 minutes\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.glassdoor.sg/Interview/Booking-com-Interview-Questions-E256653.htm' # Change URL to company you want\n",
    "next_url = None\n",
    "page = 1\n",
    "num = 0\n",
    "main_dict = []\n",
    "prevent = [37,71]\n",
    "max_page = 188            # Change the page number to the number of pages you want to web scrape\n",
    "start_time = time.time()\n",
    "\n",
    "print('Scraping page :')\n",
    "\n",
    "while page < max_page:\n",
    "    if next_url == None:\n",
    "        next_url = url    \n",
    "    \n",
    "    else:\n",
    "        next_url = 'https://www.glassdoor.com'+after\n",
    "    \n",
    "    if page % prevent[num] == 0:\n",
    "        print(f'Pause to rest. Run time : {round((time.time() - start_time)/60,2)} minutes\\n')\n",
    "        time.sleep(random.randint(3,5))\n",
    "        print('Scraping page :')\n",
    "        num = 1 - num\n",
    "    \n",
    "    driver.get(next_url)\n",
    "    time.sleep(random.randint(1,3))\n",
    "    \n",
    "    post = html.fromstring(driver.page_source)\n",
    "    get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    " \n",
    "    while len(get_id) < 10:\n",
    "        print(f'Refreshing page {page}...')\n",
    "        driver.get(next_url)\n",
    "        time.sleep(random.randint(2,4))\n",
    "        post = html.fromstring(driver.page_source)\n",
    "        get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    "\n",
    "    for i in range(len(get_id)):\n",
    "        \n",
    "        id_pos = get_id[i].attrib['id']\n",
    "        interview_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[1]/p[4]/text()')\n",
    "        question_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[2]/ul/li/span/text()')\n",
    "        offer_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[1]/div/div[2]/span/text()')\n",
    "        experience_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[2]/div/div[2]/span/text()')\n",
    "        difficulty_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[3]/div/div[2]/span/text()')\n",
    "        \n",
    "        page_frame = {}\n",
    "        \n",
    "        if len(interview_) == 1:\n",
    "            page_frame['interview'] = interview_[0]\n",
    "            \n",
    "        if len(question_) == 1:\n",
    "            page_frame['question'] = question_[0]\n",
    "        \n",
    "        if len(offer_) == 1:\n",
    "            page_frame['offer'] = offer_[0]\n",
    "\n",
    "        if len(experience_) == 1:\n",
    "            page_frame['experience'] = experience_[0]\n",
    "\n",
    "        if len(difficulty_) == 1:\n",
    "            page_frame['difficulty'] = difficulty_[0]\n",
    "        \n",
    "        main_dict.append(page_frame)\n",
    "\n",
    "    if page % 50 == 0:\n",
    "        print(f'{page} of {max_page-1}, Run time : {round((time.time() - start_time)/60,2)} minutes')\n",
    "        \n",
    "    else:\n",
    "        print(f'{page} of {max_page-1}')\n",
    "    \n",
    "    page+=1\n",
    "    after = post.xpath('//*[@id=\"FooterPageNav\"]/div[2]/ul/li[7]/a/@href')[0]\n",
    "    bookingcom_df = pd.DataFrame(main_dict)                                        # Change the data frame and csv name\n",
    "\n",
    "print(f'\\nSuccessfully scraped for bookingcom interviews.\\nTotal duration : {round((time.time() - start_time)/60,2)} minutes')\n",
    "# Change the name of company you are scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page :\n",
      "1 of 105\n",
      "2 of 105\n",
      "3 of 105\n",
      "4 of 105\n",
      "5 of 105\n",
      "6 of 105\n",
      "7 of 105\n",
      "8 of 105\n",
      "9 of 105\n",
      "10 of 105\n",
      "11 of 105\n",
      "12 of 105\n",
      "13 of 105\n",
      "14 of 105\n",
      "15 of 105\n",
      "16 of 105\n",
      "17 of 105\n",
      "18 of 105\n",
      "19 of 105\n",
      "20 of 105\n",
      "21 of 105\n",
      "22 of 105\n",
      "23 of 105\n",
      "24 of 105\n",
      "25 of 105\n",
      "26 of 105\n",
      "27 of 105\n",
      "28 of 105\n",
      "29 of 105\n",
      "30 of 105\n",
      "31 of 105\n",
      "32 of 105\n",
      "33 of 105\n",
      "34 of 105\n",
      "35 of 105\n",
      "36 of 105\n",
      "Pause to rest. Run time : 4.0 minutes\n",
      "\n",
      "Scraping page :\n",
      "37 of 105\n",
      "38 of 105\n",
      "39 of 105\n",
      "40 of 105\n",
      "41 of 105\n",
      "42 of 105\n",
      "43 of 105\n",
      "44 of 105\n",
      "45 of 105\n",
      "46 of 105\n",
      "47 of 105\n",
      "48 of 105\n",
      "49 of 105\n",
      "50 of 105, Run time : 5.99 minutes\n",
      "51 of 105\n",
      "52 of 105\n",
      "53 of 105\n",
      "54 of 105\n",
      "55 of 105\n",
      "56 of 105\n",
      "57 of 105\n",
      "58 of 105\n",
      "59 of 105\n",
      "60 of 105\n",
      "61 of 105\n",
      "62 of 105\n",
      "63 of 105\n",
      "64 of 105\n",
      "65 of 105\n",
      "66 of 105\n",
      "67 of 105\n",
      "68 of 105\n",
      "69 of 105\n",
      "70 of 105\n",
      "Pause to rest. Run time : 8.37 minutes\n",
      "\n",
      "Scraping page :\n",
      "71 of 105\n",
      "72 of 105\n",
      "73 of 105\n",
      "Pause to rest. Run time : 8.76 minutes\n",
      "\n",
      "Scraping page :\n",
      "74 of 105\n",
      "75 of 105\n",
      "76 of 105\n",
      "77 of 105\n",
      "78 of 105\n",
      "79 of 105\n",
      "80 of 105\n",
      "81 of 105\n",
      "82 of 105\n",
      "83 of 105\n",
      "84 of 105\n",
      "85 of 105\n",
      "86 of 105\n",
      "87 of 105\n",
      "88 of 105\n",
      "89 of 105\n",
      "90 of 105\n",
      "91 of 105\n",
      "92 of 105\n",
      "93 of 105\n",
      "94 of 105\n",
      "95 of 105\n",
      "96 of 105\n",
      "97 of 105\n",
      "98 of 105\n",
      "99 of 105\n",
      "100 of 105, Run time : 12.23 minutes\n",
      "101 of 105\n",
      "102 of 105\n",
      "103 of 105\n",
      "104 of 105\n",
      "105 of 105\n",
      "\n",
      "Successfully scraped for groupon interviews.\n",
      "Total duration : 12.82 minutes\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.glassdoor.sg/Interview/Groupon-Interview-Questions-E301291.htm' # Change URL to company you want\n",
    "next_url = None\n",
    "page = 1\n",
    "num = 0\n",
    "main_dict = []\n",
    "prevent = [37,71]\n",
    "max_page = 106            # Change the page number to the number of pages you want to web scrape\n",
    "start_time = time.time()\n",
    "\n",
    "print('Scraping page :')\n",
    "\n",
    "while page < max_page:\n",
    "    if next_url == None:\n",
    "        next_url = url    \n",
    "    \n",
    "    else:\n",
    "        next_url = 'https://www.glassdoor.com'+after\n",
    "    \n",
    "    if page % prevent[num] == 0:\n",
    "        print(f'Pause to rest. Run time : {round((time.time() - start_time)/60,2)} minutes\\n')\n",
    "        time.sleep(random.randint(3,5))\n",
    "        print('Scraping page :')\n",
    "        num = 1 - num\n",
    "    \n",
    "    driver.get(next_url)\n",
    "    time.sleep(random.randint(1,3))\n",
    "    \n",
    "    post = html.fromstring(driver.page_source)\n",
    "    get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    " \n",
    "    while len(get_id) < 10:\n",
    "        print(f'Refreshing page {page}...')\n",
    "        driver.get(next_url)\n",
    "        time.sleep(random.randint(2,4))\n",
    "        post = html.fromstring(driver.page_source)\n",
    "        get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    "\n",
    "    for i in range(len(get_id)):\n",
    "        \n",
    "        id_pos = get_id[i].attrib['id']\n",
    "        interview_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[1]/p[4]/text()')\n",
    "        question_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[2]/ul/li/span/text()')\n",
    "        offer_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[1]/div/div[2]/span/text()')\n",
    "        experience_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[2]/div/div[2]/span/text()')\n",
    "        difficulty_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[3]/div/div[2]/span/text()')\n",
    "        \n",
    "        page_frame = {}\n",
    "        \n",
    "        if len(interview_) == 1:\n",
    "            page_frame['interview'] = interview_[0]\n",
    "            \n",
    "        if len(question_) == 1:\n",
    "            page_frame['question'] = question_[0]\n",
    "        \n",
    "        if len(offer_) == 1:\n",
    "            page_frame['offer'] = offer_[0]\n",
    "\n",
    "        if len(experience_) == 1:\n",
    "            page_frame['experience'] = experience_[0]\n",
    "\n",
    "        if len(difficulty_) == 1:\n",
    "            page_frame['difficulty'] = difficulty_[0]\n",
    "        \n",
    "        main_dict.append(page_frame)\n",
    "\n",
    "    if page % 50 == 0:\n",
    "        print(f'{page} of {max_page-1}, Run time : {round((time.time() - start_time)/60,2)} minutes')\n",
    "        \n",
    "    else:\n",
    "        print(f'{page} of {max_page-1}')\n",
    "    \n",
    "    page+=1\n",
    "    after = post.xpath('//*[@id=\"FooterPageNav\"]/div[2]/ul/li[7]/a/@href')[0]\n",
    "    groupon_df = pd.DataFrame(main_dict)                                        # Change the data frame and csv name\n",
    "\n",
    "print(f'\\nSuccessfully scraped for groupon interviews.\\nTotal duration : {round((time.time() - start_time)/60,2)} minutes')\n",
    "# Change the name of company you are scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page :\n",
      "1 of 25\n",
      "2 of 25\n",
      "3 of 25\n",
      "4 of 25\n",
      "5 of 25\n",
      "6 of 25\n",
      "Pause to rest. Run time : 0.6 minutes\n",
      "\n",
      "Scraping page :\n",
      "7 of 25\n",
      "8 of 25\n",
      "9 of 25\n",
      "10 of 25\n",
      "Pause to rest. Run time : 1.1 minutes\n",
      "\n",
      "Scraping page :\n",
      "11 of 25\n",
      "12 of 25\n",
      "13 of 25\n",
      "Pause to rest. Run time : 1.47 minutes\n",
      "\n",
      "Scraping page :\n",
      "14 of 25\n",
      "15 of 25\n",
      "16 of 25\n",
      "17 of 25\n",
      "18 of 25\n",
      "19 of 25\n",
      "20 of 25\n",
      "21 of 25\n",
      "Pause to rest. Run time : 2.29 minutes\n",
      "\n",
      "Scraping page :\n",
      "22 of 25\n",
      "23 of 25\n",
      "24 of 25\n",
      "25 of 25\n",
      "\n",
      "Successfully scraped for Tiktok interviews.\n",
      "Total duration : 2.95 minutes\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.glassdoor.sg/Interview/TikTok-Interview-Questions-E2230881.htm' # Change URL to company you want\n",
    "next_url = None\n",
    "page = 1\n",
    "num = 0\n",
    "main_dict = []\n",
    "prevent = [7,11]\n",
    "max_page = 26            # Change the page number to the number of pages you want to web scrape\n",
    "start_time = time.time()\n",
    "\n",
    "print('Scraping page :')\n",
    "\n",
    "while page < max_page:\n",
    "    if next_url == None:\n",
    "        next_url = url    \n",
    "    \n",
    "    else:\n",
    "        next_url = 'https://www.glassdoor.com'+after\n",
    "    \n",
    "    if page % prevent[num] == 0:\n",
    "        print(f'Pause to rest. Run time : {round((time.time() - start_time)/60,2)} minutes\\n')\n",
    "        time.sleep(random.randint(3,5))\n",
    "        print('Scraping page :')\n",
    "        num = 1 - num\n",
    "    \n",
    "    driver.get(next_url)\n",
    "    time.sleep(random.randint(1,3))\n",
    "    \n",
    "    post = html.fromstring(driver.page_source)\n",
    "    get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    " \n",
    "    while len(get_id) < 10:\n",
    "        print(f'Refreshing page {page}...')\n",
    "        driver.get(next_url)\n",
    "        time.sleep(random.randint(2,4))\n",
    "        post = html.fromstring(driver.page_source)\n",
    "        get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    "\n",
    "    for i in range(len(get_id)):\n",
    "        \n",
    "        id_pos = get_id[i].attrib['id']\n",
    "        interview_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[1]/p[4]/text()')\n",
    "        question_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[2]/ul/li/span/text()')\n",
    "        offer_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[1]/div/div[2]/span/text()')\n",
    "        experience_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[2]/div/div[2]/span/text()')\n",
    "        difficulty_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[3]/div/div[2]/span/text()')\n",
    "        \n",
    "        page_frame = {}\n",
    "        \n",
    "        if len(interview_) == 1:\n",
    "            page_frame['interview'] = interview_[0]\n",
    "            \n",
    "        if len(question_) == 1:\n",
    "            page_frame['question'] = question_[0]\n",
    "        \n",
    "        if len(offer_) == 1:\n",
    "            page_frame['offer'] = offer_[0]\n",
    "\n",
    "        if len(experience_) == 1:\n",
    "            page_frame['experience'] = experience_[0]\n",
    "\n",
    "        if len(difficulty_) == 1:\n",
    "            page_frame['difficulty'] = difficulty_[0]\n",
    "        \n",
    "        main_dict.append(page_frame)\n",
    "\n",
    "    if page % 50 == 0:\n",
    "        print(f'{page} of {max_page-1}, Run time : {round((time.time() - start_time)/60,2)} minutes')\n",
    "        \n",
    "    else:\n",
    "        print(f'{page} of {max_page-1}')\n",
    "    \n",
    "    page+=1\n",
    "    after = post.xpath('//*[@id=\"FooterPageNav\"]/div[2]/ul/li[7]/a/@href')[0]\n",
    "    tiktok_df = pd.DataFrame(main_dict)                                        # Change the data frame and csv name\n",
    "\n",
    "print(f'\\nSuccessfully scraped for Tiktok interviews.\\nTotal duration : {round((time.time() - start_time)/60,2)} minutes')\n",
    "# Change the name of company you are scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page :\n",
      "1 of 22\n",
      "2 of 22\n",
      "3 of 22\n",
      "4 of 22\n",
      "5 of 22\n",
      "6 of 22\n",
      "Pause to rest. Run time : 0.5 minutes\n",
      "\n",
      "Scraping page :\n",
      "7 of 22\n",
      "8 of 22\n",
      "9 of 22\n",
      "10 of 22\n",
      "Pause to rest. Run time : 0.87 minutes\n",
      "\n",
      "Scraping page :\n",
      "11 of 22\n",
      "12 of 22\n",
      "13 of 22\n",
      "Pause to rest. Run time : 1.13 minutes\n",
      "\n",
      "Scraping page :\n",
      "14 of 22\n",
      "15 of 22\n",
      "16 of 22\n",
      "17 of 22\n",
      "18 of 22\n",
      "19 of 22\n",
      "20 of 22\n",
      "21 of 22\n",
      "Pause to rest. Run time : 1.8 minutes\n",
      "\n",
      "Scraping page :\n",
      "22 of 22\n",
      "\n",
      "Successfully scraped for ByteDance_df interviews.\n",
      "Total duration : 1.92 minutes\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.glassdoor.sg/Interview/ByteDance-Interview-Questions-E1624196.htm' # Change URL to company you want\n",
    "next_url = None\n",
    "page = 1\n",
    "num = 0\n",
    "main_dict = []\n",
    "prevent = [7,11]\n",
    "max_page = 23            # Change the page number to the number of pages you want to web scrape\n",
    "start_time = time.time()\n",
    "\n",
    "print('Scraping page :')\n",
    "\n",
    "while page < max_page:\n",
    "    if next_url == None:\n",
    "        next_url = url    \n",
    "    \n",
    "    else:\n",
    "        next_url = 'https://www.glassdoor.com'+after\n",
    "    \n",
    "    if page % prevent[num] == 0:\n",
    "        print(f'Pause to rest. Run time : {round((time.time() - start_time)/60,2)} minutes\\n')\n",
    "        time.sleep(random.randint(3,5))\n",
    "        print('Scraping page :')\n",
    "        num = 1 - num\n",
    "    \n",
    "    driver.get(next_url)\n",
    "    time.sleep(random.randint(1,3))\n",
    "    \n",
    "    post = html.fromstring(driver.page_source)\n",
    "    get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    " \n",
    "    while len(get_id) < 10:\n",
    "        print(f'Refreshing page {page}...')\n",
    "        driver.get(next_url)\n",
    "        time.sleep(random.randint(2,4))\n",
    "        post = html.fromstring(driver.page_source)\n",
    "        get_id = post.xpath('//*[contains(@id,\"InterviewReview\")]')[1:]\n",
    "\n",
    "    for i in range(len(get_id)):\n",
    "        \n",
    "        id_pos = get_id[i].attrib['id']\n",
    "        interview_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[1]/p[4]/text()')\n",
    "        question_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[2]/div/div[2]/ul/li/span/text()')\n",
    "        offer_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[1]/div/div[2]/span/text()')\n",
    "        experience_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[2]/div/div[2]/span/text()')\n",
    "        difficulty_ = post.xpath(f'//*[@id=\"{id_pos}\"]/div[3]/div/div[2]/div[1]/div/div[3]/div/div[2]/span/text()')\n",
    "        \n",
    "        page_frame = {}\n",
    "        \n",
    "        if len(interview_) == 1:\n",
    "            page_frame['interview'] = interview_[0]\n",
    "            \n",
    "        if len(question_) == 1:\n",
    "            page_frame['question'] = question_[0]\n",
    "        \n",
    "        if len(offer_) == 1:\n",
    "            page_frame['offer'] = offer_[0]\n",
    "\n",
    "        if len(experience_) == 1:\n",
    "            page_frame['experience'] = experience_[0]\n",
    "\n",
    "        if len(difficulty_) == 1:\n",
    "            page_frame['difficulty'] = difficulty_[0]\n",
    "        \n",
    "        main_dict.append(page_frame)\n",
    "\n",
    "    if page % 50 == 0:\n",
    "        print(f'{page} of {max_page-1}, Run time : {round((time.time() - start_time)/60,2)} minutes')\n",
    "        \n",
    "    else:\n",
    "        print(f'{page} of {max_page-1}')\n",
    "    \n",
    "    page+=1\n",
    "    after = post.xpath('//*[@id=\"FooterPageNav\"]/div[2]/ul/li[7]/a/@href')[0]\n",
    "    bytedance_df = pd.DataFrame(main_dict)                                        # Change the data frame and csv name\n",
    "\n",
    "print(f'\\nSuccessfully scraped for ByteDance_df interviews.\\nTotal duration : {round((time.time() - start_time)/60,2)} minutes')\n",
    "# Change the name of company you are scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ebay_df['source'] = 'ebay'\n",
    "paypal_df['source'] = 'paypal'\n",
    "hubspot_df['source'] = 'hubspot'\n",
    "docusign_df['source'] = 'docusign'\n",
    "nvidia_df['source'] = 'nvidia'\n",
    "oracle_df['source'] = 'oracle'\n",
    "uber_df['source'] = 'uber'\n",
    "twitter_df['source'] = 'twitter'\n",
    "lyft_df['source'] = 'lyft'\n",
    "pinterest_df['source'] = 'pinterest'\n",
    "airbnb_df['source'] = 'airbnb'\n",
    "yelp_df['source'] = 'yelp'\n",
    "bookingcom_df['source'] = 'bookingcom'\n",
    "groupon_df['source'] = 'groupon'\n",
    "tiktok_df['source'] = 'tiktok'\n",
    "bytedance_df['source'] = 'bytedance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([ebay_df,paypal_df,hubspot_df,docusign_df,nvidia_df,oracle_df,uber_df,twitter_df,lyft_df,\n",
    "                pinterest_df,airbnb_df,yelp_df,bookingcom_df,groupon_df,tiktok_df,bytedance_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.to_csv('../datasets/extra_reviews2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['interview'].fillna('', inplace = True)\n",
    "df['question'].fillna('', inplace = True)\n",
    "# fill all nan with ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['experience'] == 'Negative Experience']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-eee345e0123d>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['experience'] = df['experience'].apply(lambda exp : 1 if exp == 'Positive Experience' else 0)\n"
     ]
    }
   ],
   "source": [
    "df['experience'] = df['experience'].apply(lambda exp : 1 if exp == 'Positive Experience' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-875fdd15f382>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['length'] = df['interview'].apply(len)\n"
     ]
    }
   ],
   "source": [
    "df['length'] = df['interview'].apply(len)\n",
    "df = df[df['length']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df.length <= 1000) & (df.length >= 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'experience' : 'target_variable'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../datasets/badreviewsonly2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2644\n",
       "Name: target_variable, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target_variable.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>interview</th>\n",
       "      <th>question</th>\n",
       "      <th>offer</th>\n",
       "      <th>target_variable</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>source</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Poorly designed; implementation heavy but not ...</td>\n",
       "      <td>Coding assessment on code signal</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>0</td>\n",
       "      <td>Average Interview</td>\n",
       "      <td>ebay</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Did a code signal assessment. It was about bas...</td>\n",
       "      <td>Did not get to the interview section</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ebay</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Recruiter reached out to setup TPS. I believe ...</td>\n",
       "      <td>Leet code 'medium' category problem</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>0</td>\n",
       "      <td>Easy Interview</td>\n",
       "      <td>ebay</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Contacted by HR. Then followed by a technical ...</td>\n",
       "      <td>Design some ebay API + coding LC medium top 1...</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>0</td>\n",
       "      <td>Average Interview</td>\n",
       "      <td>ebay</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Recruiter reached out to me via Indeed and nev...</td>\n",
       "      <td>You look like a good candidate for this posit...</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>0</td>\n",
       "      <td>Difficult Interview</td>\n",
       "      <td>ebay</td>\n",
       "      <td>513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23136</th>\n",
       "      <td>A new office was supposed to operate in Dubai ...</td>\n",
       "      <td>How would you promote influencers to create m...</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>0</td>\n",
       "      <td>Average Interview</td>\n",
       "      <td>bytedance</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23139</th>\n",
       "      <td>Applied the position online and very soon the ...</td>\n",
       "      <td>How do you think the real work for HRBP? why ...</td>\n",
       "      <td>Declined Offer</td>\n",
       "      <td>0</td>\n",
       "      <td>Average Interview</td>\n",
       "      <td>bytedance</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23140</th>\n",
       "      <td>Online tests first, then notified of telephone...</td>\n",
       "      <td>What single metric to use to measure how well...</td>\n",
       "      <td>No Offer</td>\n",
       "      <td>0</td>\n",
       "      <td>Average Interview</td>\n",
       "      <td>bytedance</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23145</th>\n",
       "      <td>I applied online and within 5 days they sent m...</td>\n",
       "      <td>Please introuduce yourself, constantly: 'what...</td>\n",
       "      <td>Declined Offer</td>\n",
       "      <td>0</td>\n",
       "      <td>Easy Interview</td>\n",
       "      <td>bytedance</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23156</th>\n",
       "      <td>Happened over video call since the team was ba...</td>\n",
       "      <td>Questions related to influencer marketing, ot...</td>\n",
       "      <td>Accepted Offer</td>\n",
       "      <td>0</td>\n",
       "      <td>Average Interview</td>\n",
       "      <td>bytedance</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2644 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               interview  \\\n",
       "2      Poorly designed; implementation heavy but not ...   \n",
       "3      Did a code signal assessment. It was about bas...   \n",
       "12     Recruiter reached out to setup TPS. I believe ...   \n",
       "23     Contacted by HR. Then followed by a technical ...   \n",
       "25     Recruiter reached out to me via Indeed and nev...   \n",
       "...                                                  ...   \n",
       "23136  A new office was supposed to operate in Dubai ...   \n",
       "23139  Applied the position online and very soon the ...   \n",
       "23140  Online tests first, then notified of telephone...   \n",
       "23145  I applied online and within 5 days they sent m...   \n",
       "23156  Happened over video call since the team was ba...   \n",
       "\n",
       "                                                question           offer  \\\n",
       "2                    Coding assessment on code signal           No Offer   \n",
       "3                Did not get to the interview section           No Offer   \n",
       "12                Leet code 'medium' category problem           No Offer   \n",
       "23      Design some ebay API + coding LC medium top 1...        No Offer   \n",
       "25      You look like a good candidate for this posit...        No Offer   \n",
       "...                                                  ...             ...   \n",
       "23136   How would you promote influencers to create m...        No Offer   \n",
       "23139   How do you think the real work for HRBP? why ...  Declined Offer   \n",
       "23140   What single metric to use to measure how well...        No Offer   \n",
       "23145   Please introuduce yourself, constantly: 'what...  Declined Offer   \n",
       "23156   Questions related to influencer marketing, ot...  Accepted Offer   \n",
       "\n",
       "       target_variable           difficulty     source  length  \n",
       "2                    0    Average Interview       ebay     215  \n",
       "3                    0                  NaN       ebay     223  \n",
       "12                   0       Easy Interview       ebay     448  \n",
       "23                   0    Average Interview       ebay     482  \n",
       "25                   0  Difficult Interview       ebay     513  \n",
       "...                ...                  ...        ...     ...  \n",
       "23136                0    Average Interview  bytedance     366  \n",
       "23139                0    Average Interview  bytedance     708  \n",
       "23140                0    Average Interview  bytedance     260  \n",
       "23145                0       Easy Interview  bytedance     600  \n",
       "23156                0    Average Interview  bytedance     300  \n",
       "\n",
       "[2644 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
